{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# arXiv Bilingual Reader - TranslateGemma\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jimmyliao/trans-gemma/blob/main/arxiv-reader.ipynb)\n\n**ğŸ“– é›™èªå°ç…§é–±è®€ arXiv è«–æ–‡ï¼Œæå‡è‹±æ–‡å­¸è¡“å¯«ä½œèƒ½åŠ›**\n\n---\n\n## âœ¨ åŠŸèƒ½ç‰¹è‰²\n\n- ğŸ¯ **é›™èªä¸¦æ’**: åŸæ–‡èˆ‡ç¿»è­¯ä¸¦åˆ—ï¼Œæ–¹ä¾¿å°ç…§å­¸ç¿’\n- ğŸ“š **ç« ç¯€åˆ†çµ„**: ä¾ Abstractã€Methodsã€Results ç­‰çµæ§‹åŒ–çµ„ç¹”\n- ğŸ’¾ **äº’å‹•å¼ HTML**: ç”Ÿæˆå¯é›¢ç·šé–±è®€çš„ç¶²é ï¼Œæ”¯æ´éµç›¤å°èˆªï¼ˆâ† â†’ éµï¼‰\n- ğŸ”¤ **è¡“èªè¡¨**: è‡ªå‹•æå–å°ˆæ¥­è¡“èªåŠå…¶ç¿»è­¯\n- ğŸ‡¹ğŸ‡¼ **ç¹é«”å„ªåŒ–**: é‡å°å°ç£ç¹é«”ä¸­æ–‡å„ªåŒ–\n\n---\n\n## ğŸ¯ é©åˆå°è±¡\n\n- âœ… **ç ”ç©¶ç”Ÿ**: é–±è®€æ–‡ç»ã€æº–å‚™è«–æ–‡å¯«ä½œ\n- âœ… **å·¥ç¨‹å¸«**: è¿½è¹¤æœ€æ–°æŠ€è¡“ã€ç†è§£å‰æ²¿ç ”ç©¶\n- âœ… **è‹±æ–‡å­¸ç¿’è€…**: å­¸ç¿’å­¸è¡“è‹±æ–‡è¡¨é”æ–¹å¼\n\n---\n\n## ğŸš€ æ”¯æ´ç’°å¢ƒ\n\næ­¤ notebook æœƒ**è‡ªå‹•åµæ¸¬**åŸ·è¡Œç’°å¢ƒä¸¦èª¿æ•´è¨­å®šï¼š\n\n- âœ… **Google Colab** (Free T4 GPU) - æ¨è–¦æ–°æ‰‹\n- âœ… **GCP Custom Runtime** (T4 GPU) - é€²éšç”¨æˆ¶\n- âœ… **æœ¬åœ° Jupyter** (CPU/GPU) - æœ‰ GPU è¨­å‚™\n\n---\n\n## âš¡ å¿«é€Ÿé–‹å§‹\n\n### Google Colab (æ¨è–¦)\n1. é»æ“Šä¸Šæ–¹ \"Open In Colab\" æŒ‰éˆ•\n2. Runtime â†’ Change runtime type â†’ **T4 GPU** â†’ Save\n3. æŒ‰é †åºåŸ·è¡Œæ‰€æœ‰ cellsï¼ˆæˆ– Runtime â†’ Run allï¼‰\n\n### é æœŸæ™‚é–“\n- **é¦–æ¬¡åŸ·è¡Œ**: ~10 åˆ†é˜ï¼ˆå«ä¸‹è¼‰æ¨¡å‹ 8GBï¼‰\n- **ä¹‹å¾ŒåŸ·è¡Œ**: ~5 åˆ†é˜ï¼ˆæ¨¡å‹å·²å¿«å–ï¼‰\n- **ç¿»è­¯é€Ÿåº¦**: ~3 åˆ†é˜/é \n\n---\n\n## ğŸ‘¤ ä½œè€…\n\n**Jimmy Liao** ([GitHub](https://github.com/jimmyliao) | [Blog](https://jimmyliao.dev))\n- Google AI GDE (Generative AI)\n- Microsoft MVP (AI)\n- AI Startup CTO\n\n---\n\n**License**: MIT | **Model**: TranslateGemma 4B | **Source**: [GitHub](https://github.com/jimmyliao/trans-gemma)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: ç’°å¢ƒåµæ¸¬ & è¨­å®š\n",
    "\n",
    "**è‡ªå‹•åµæ¸¬åŸ·è¡Œç’°å¢ƒä¸¦é…ç½®**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ” Environment Detection\n",
      "================================================================================\n",
      "ğŸ–¥ï¸  Environment: GCP\n",
      "ğŸ Python: 3.10\n",
      "ğŸ“‚ Working dir: /root\n",
      "================================================================================\n",
      "âœ… Environment: GCP - Ready!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# åµæ¸¬ç’°å¢ƒ\n",
    "def detect_environment():\n",
    "    \"\"\"Detect runtime environment\"\"\"\n",
    "    # Check if running in Google Colab\n",
    "    try:\n",
    "        import google.colab\n",
    "        return 'colab'\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Check if running on GCP (check for conda py310)\n",
    "    if os.path.exists('/opt/conda/bin/conda'):\n",
    "        result = os.popen('/opt/conda/bin/conda env list').read()\n",
    "        if 'py310' in result:\n",
    "            return 'gcp'\n",
    "    \n",
    "    # Default: local Jupyter\n",
    "    return 'local'\n",
    "\n",
    "ENV = detect_environment()\n",
    "PYTHON_VERSION = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ” Environment Detection\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ğŸ–¥ï¸  Environment: {ENV.upper()}\")\n",
    "print(f\"ğŸ Python: {PYTHON_VERSION}\")\n",
    "print(f\"ğŸ“‚ Working dir: {os.getcwd()}\")\n",
    "\n",
    "# Environment-specific warnings\n",
    "if ENV == 'gcp' and sys.version_info.minor < 10:\n",
    "    print(\"\\nâš ï¸  WARNING: GCP detected but Python < 3.10\")\n",
    "    print(\"   Please select 'Python 3.10 (trans-gemma)' kernel\")\n",
    "    print(\"   (Click top-right kernel selector â†’ Python 3.10)\")\n",
    "    raise RuntimeError(\"Wrong kernel selected\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ… Environment: {ENV.upper()} - Ready!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç•¶å‰ Python: /opt/conda/envs/py310/bin/python\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "âœ… å®‰è£å®Œæˆï¼\n"
     ]
    }
   ],
   "source": "### ğŸ” é©—è­‰ï¼šç›´æ¥å®‰è£åˆ°ç•¶å‰ç’°å¢ƒï¼ˆå¯é¸ï¼‰\n\nå¦‚æœ Step 1 å®‰è£å¤±æ•—æˆ–ç’°å¢ƒä¸ä¸€è‡´ï¼Œå¯ä»¥åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ç›´æ¥å®‰è£åˆ°ç•¶å‰ Python ç’°å¢ƒï¼š\n\n```python\nimport sys\nprint(f\"ç•¶å‰ Python: {sys.executable}\")\n!{sys.executable} -m pip install huggingface_hub transformers accelerate sentencepiece protobuf pymupdf pillow tqdm ipywidgets opencc-python-reimplemented -q\nprint(\"\\nâœ… å®‰è£å®Œæˆï¼\")\n```\n\n> **æ³¨æ„**: æ­£å¸¸æƒ…æ³ä¸‹åŸ·è¡Œ Step 1 å³å¯ï¼Œæ­¤ç‚ºå‚™ç”¨æ–¹æ¡ˆã€‚å¦‚éœ€ä½¿ç”¨ï¼Œè«‹å°‡ä¸Šæ–¹ç¨‹å¼ç¢¼è¤‡è£½åˆ°æ–° cell åŸ·è¡Œã€‚"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: å®‰è£å¥—ä»¶\n",
    "\n",
    "**æ ¹æ“šç’°å¢ƒè‡ªå‹•å®‰è£å¿…è¦å¥—ä»¶**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Installing packages for GCP environment...\n",
      "\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mâœ… GCP packages installed\n",
      "\n",
      "âœ… All packages ready!\n"
     ]
    }
   ],
   "source": [
    "print(f\"ğŸ“¦ Installing packages for {ENV.upper()} environment...\\n\")",
    "",
    "if ENV == 'colab':",
    "    # Google Colab: ä½¿ç”¨ç³»çµ± Python (å·²ç¶“æ˜¯ 3.10+)",
    "    !pip install -q huggingface_hub transformers accelerate sentencepiece protobuf pymupdf pillow opencc-python-reimplemented",
    "    print(\"âœ… Colab packages installed\")",
    "    ",
    "elif ENV == 'gcp':",
    "    # GCP: å·²ç¶“åœ¨ py310 ç’°å¢ƒä¸­ï¼Œåªéœ€å®‰è£åŸºç¤å¥—ä»¶",
    "    !pip install -q huggingface_hub transformers accelerate sentencepiece protobuf pymupdf pillow tqdm ipywidgets opencc-python-reimplemented",
    "    print(\"âœ… GCP packages installed\")",
    "    ",
    "else:",
    "    # Local: æ¨™æº–å®‰è£",
    "    !pip install -q torch torchvision torchaudio huggingface_hub transformers accelerate sentencepiece protobuf pymupdf pillow tqdm opencc-python-reimplemented",
    "    print(\"âœ… Local packages installed\")",
    "",
    "print(\"\\nâœ… All packages ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone & Install trans-gemma\n",
    "\n",
    "**å–å¾—æœ€æ–°ç¨‹å¼ç¢¼**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Updating trans-gemma...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hint: Pulling without specifying how to reconcile divergent branches is\n",
      "hint: discouraged. You can squelch this message by running one of the following\n",
      "hint: commands sometime before your next pull:\n",
      "hint: \n",
      "hint:   git config pull.rebase false  # merge (the default strategy)\n",
      "hint:   git config pull.rebase true   # rebase\n",
      "hint:   git config pull.ff only       # fast-forward only\n",
      "hint: \n",
      "hint: You can replace \"git config\" with \"git config --global\" to set a default\n",
      "hint: preference for all repositories. You can also pass --rebase, --no-rebase,\n",
      "hint: or --ff-only on the command line to override the configured default per\n",
      "hint: invocation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Package 'trans-gemma' requires a different Python: 3.9.2 not in '>=3.10'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… trans-gemma installed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Clone or update repository\n",
    "if [ -d \"trans-gemma\" ]; then\n",
    "    echo \"ğŸ“ Updating trans-gemma...\"\n",
    "    cd trans-gemma && git pull\n",
    "else\n",
    "    echo \"ğŸ“¥ Cloning trans-gemma...\"\n",
    "    git clone https://github.com/jimmyliao/trans-gemma.git\n",
    "fi\n",
    "\n",
    "# Install\n",
    "cd trans-gemma\n",
    "pip install -q -e \".[examples]\"\n",
    "\n",
    "echo \"âœ… trans-gemma installed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: HuggingFace èªè­‰\n",
    "\n",
    "**ğŸ” è¨­å®š Token**\n",
    "\n",
    "éœ€è¦ï¼š\n",
    "1. Token: https://huggingface.co/settings/tokens\n",
    "2. æ¥å—æ¨¡å‹: https://huggingface.co/google/gemma-2-2b-it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ Please enter HuggingFace Token:\n",
      "   1. Get token: https://huggingface.co/settings/tokens\n",
      "   2. Accept model: https://huggingface.co/google/gemma-2-2b-it\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Saved to .env\n",
      "\n",
      "âœ… HuggingFace authentication complete!\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ä¾ç’°å¢ƒé¸æ“‡èªè­‰æ–¹å¼\n",
    "env_file = Path('trans-gemma/.env')\n",
    "token = None\n",
    "\n",
    "# Method 1: .env file (GCP/Local)\n",
    "if env_file.exists():\n",
    "    with open(env_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip().startswith('HF_TOKEN='):\n",
    "                token = line.split('=', 1)[1].strip().strip('\"').strip(\"'\")\n",
    "                print(\"âœ… Loaded from .env\")\n",
    "                break\n",
    "\n",
    "# Method 2: Colab Secrets\n",
    "if not token and ENV == 'colab':\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        token = userdata.get('HF_TOKEN')\n",
    "        print(\"âœ… Loaded from Colab Secrets\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Method 3: Environment variable\n",
    "if not token:\n",
    "    token = os.getenv('HF_TOKEN') or os.getenv('HUGGING_FACE_HUB_TOKEN')\n",
    "    if token:\n",
    "        print(\"âœ… Loaded from environment\")\n",
    "\n",
    "# Method 4: Manual input\n",
    "if not token:\n",
    "    print(\"\\nğŸ“ Please enter HuggingFace Token:\")\n",
    "    if ENV == 'colab':\n",
    "        print(\"   ğŸ’¡ Tip: Use Colab Secrets (ğŸ”‘ icon) for better security\")\n",
    "    print(\"   1. Get token: https://huggingface.co/settings/tokens\")\n",
    "    print(\"   2. Accept model: https://huggingface.co/google/gemma-2-2b-it\\n\")\n",
    "    \n",
    "    token = input(\"Token: \").strip()\n",
    "    \n",
    "    # Save to .env (not for Colab)\n",
    "    if ENV != 'colab':\n",
    "        env_file.parent.mkdir(exist_ok=True)\n",
    "        with open(env_file, 'w') as f:\n",
    "            f.write(f\"HF_TOKEN={token}\\n\")\n",
    "        print(\"ğŸ’¾ Saved to .env\")\n",
    "\n",
    "# Login\n",
    "os.environ['HF_TOKEN'] = token\n",
    "login(token=token)\n",
    "print(\"\\nâœ… HuggingFace authentication complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: GPU æª¢æŸ¥\n",
    "\n",
    "**ç¢ºèª GPU å¯ç”¨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ® GPU Check\n",
      "================================================================================\n",
      "âœ… PyTorch: 2.5.1+cu121\n",
      "âœ… CUDA available: True\n",
      "âœ… GPU: Tesla T4\n",
      "âœ… VRAM: 14.6 GB\n",
      "\n",
      "ğŸ“Š nvidia-smi: Tesla T4, 15360 MiB\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ® GPU Check\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check PyTorch CUDA\n",
    "print(f\"âœ… PyTorch: {torch.__version__}\")\n",
    "print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"âœ… VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    \n",
    "    # Check nvidia-smi\n",
    "    try:\n",
    "        result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'],\n",
    "                              capture_output=True, text=True, timeout=3)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"\\nğŸ“Š nvidia-smi: {result.stdout.strip()}\")\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"\\nâš ï¸  WARNING: No GPU detected!\")\n",
    "    print(\"   Translation will be very slow on CPU.\")\n",
    "    if ENV == 'colab':\n",
    "        print(\"\\n   ğŸ”§ Enable GPU in Colab:\")\n",
    "        print(\"      Runtime â†’ Change runtime type â†’ T4 GPU â†’ Save\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: è¨­å®šç¿»è­¯åƒæ•¸\n",
    "\n",
    "**âœï¸ ä¿®æ”¹é€™è£¡ä¾†ç¿»è­¯ä¸åŒè«–æ–‡**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ¯ Translation Configuration\n",
      "================================================================================\n",
      "ğŸ“„ Paper: arXiv:2403.08295\n",
      "ğŸŒ en â†’ zh-TW\n",
      "ğŸ“š Sections: ['abstract']\n",
      "ğŸ“Š Pages: 1\n",
      "â±ï¸  Time: ~23s\n",
      "ğŸ’¾ HTML: Yes\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ç¿»è­¯è¨­å®šï¼ˆä¿®æ”¹é€™è£¡ï¼‰\n",
    "# ============================================\n",
    "\n",
    "# arXiv è«–æ–‡ ID\n",
    "ARXIV_ID = \"2403.08295\"  # Gemma paper\n",
    "\n",
    "# è¦ç¿»è­¯çš„ç« ç¯€ï¼ˆé ç¢¼ç¯„åœï¼‰\n",
    "SECTIONS = {\n",
    "    \"abstract\": (1, 1),  # ç¬¬ 1 é \n",
    "}\n",
    "\n",
    "# èªè¨€\n",
    "SOURCE_LANG = \"en\"\n",
    "TARGET_LANG = \"zh-TW\"\n",
    "\n",
    "# é¸é …\n",
    "SAVE_HTML = True  # å„²å­˜äº’å‹•å¼ HTML\n",
    "\n",
    "# ============================================\n",
    "# æ‘˜è¦\n",
    "# ============================================\n",
    "\n",
    "total_pages = sum(end - start + 1 for start, end in SECTIONS.values())\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ¯ Translation Configuration\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ğŸ“„ Paper: arXiv:{ARXIV_ID}\")\n",
    "print(f\"ğŸŒ {SOURCE_LANG} â†’ {TARGET_LANG}\")\n",
    "print(f\"ğŸ“š Sections: {list(SECTIONS.keys())}\")\n",
    "print(f\"ğŸ“Š Pages: {total_pages}\")\n",
    "print(f\"â±ï¸  Time: ~{total_pages * 23}s\")\n",
    "print(f\"ğŸ’¾ HTML: {'Yes' if SAVE_HTML else 'No'}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 6: è¼‰å…¥æ¨¡å‹\n\n**ğŸš€ è¼‰å…¥ TranslateGemma**\n\nâš ï¸ é¦–æ¬¡åŸ·è¡Œæœƒä¸‹è¼‰ ~8GB æ¨¡å‹"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformersBackend.__init__ åƒæ•¸ï¼š\n",
      "(self)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/root/trans-gemma/examples')\n",
    "sys.path.insert(0, '/root/trans-gemma/examples/backends')\n",
    "\n",
    "from transformers_backend import TransformersBackend\n",
    "import inspect\n",
    "\n",
    "# æª¢æŸ¥ __init__ çš„åƒæ•¸\n",
    "print(\"TransformersBackend.__init__ åƒæ•¸ï¼š\")\n",
    "print(inspect.signature(TransformersBackend.__init__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport torch\n\n# å‹•æ…‹è¨­å®š trans-gemma è·¯å¾‘\nif ENV == 'gcp':\n    base_path = '/root/trans-gemma'\nelse:\n    base_path = 'trans-gemma'\n\nsys.path.insert(0, f'{base_path}/examples')\nsys.path.insert(0, f'{base_path}/examples/backends')\n\nfrom transformers_backend import TransformersBackend\n\nprint(\"ğŸš€ Loading TranslateGemma (4B)...\")\nprint(\"   â³ Downloading model (~8GB) on first run...\\n\")\n\n# 1. å‰µå»º backend å¯¦ä¾‹ï¼ˆé è¨­å°±æ˜¯ translategemma-4b-itï¼‰\nbackend = TransformersBackend()\n\n# 2. è¼‰å…¥æ¨¡å‹\nresult = backend.load_model()\n\nprint(\"\\nâœ… Model loaded!\")\nprint(f\"ğŸ“ Device: {result['metadata']['device']}\")\nprint(f\"ğŸ“Š Load time: {result['load_time']:.1f}s\")\nprint(f\"ğŸ’¾ Memory: {result['metadata']['available_memory_gb']:.1f} GB available\")\nprint(\"ğŸ‰ Ready to translate!\\n\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: ä¸‹è¼‰ PDF & ç¿»è­¯\n",
    "\n",
    "**åŸ·è¡Œç¿»è­¯ä»»å‹™**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Downloading arXiv:2403.08295\n",
      "âœ… Downloaded: 2403.08295.pdf (17 pages)\n",
      "\n",
      "================================================================================\n",
      "ğŸš€ Translation Started\n",
      "================================================================================\n",
      "ğŸ“Š Pages: 1\n",
      "â±ï¸  Time: ~23s\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa6bf535d134dceb5df92ce0184195f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ğŸ“– Translating:   0%|          | 0/1 [00:00<?, ?page/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Page 1: 187.38s\n",
      "\n",
      "================================================================================\n",
      "âœ… Translation Complete!\n",
      "================================================================================\n",
      "ğŸ“Š Pages: 1\n",
      "â±ï¸  Total: 187.4s\n",
      "âš¡ Avg: 187.4s/page\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import fitz\n",
    "import time\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Download PDF\n",
    "def download_arxiv(arxiv_id):\n",
    "    clean_id = arxiv_id.split('v')[0] if 'v' in arxiv_id else arxiv_id\n",
    "    url = f\"https://arxiv.org/pdf/{clean_id}.pdf\"\n",
    "    filename = f\"{arxiv_id}.pdf\"\n",
    "    \n",
    "    print(f\"ğŸ“¥ Downloading arXiv:{arxiv_id}\")\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    \n",
    "    doc = fitz.open(filename)\n",
    "    total = len(doc)\n",
    "    doc.close()\n",
    "    \n",
    "    print(f\"âœ… Downloaded: {filename} ({total} pages)\\n\")\n",
    "    return filename, total\n",
    "\n",
    "def extract_text(pdf_path, page_num):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = doc[page_num - 1].get_text()\n",
    "    doc.close()\n",
    "    return text.strip()\n",
    "\n",
    "# Download\n",
    "pdf_path, total_pdf_pages = download_arxiv(ARXIV_ID)\n",
    "\n",
    "# Translate\n",
    "results = []\n",
    "total_to_translate = sum(end - start + 1 for start, end in SECTIONS.values())\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ Translation Started\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ğŸ“Š Pages: {total_to_translate}\")\n",
    "print(f\"â±ï¸  Time: ~{total_to_translate * 23}s\\n\")\n",
    "\n",
    "with tqdm(total=total_to_translate, desc=\"ğŸ“– Translating\", unit=\"page\") as pbar:\n",
    "    for section, (start, end) in SECTIONS.items():\n",
    "        for page_num in range(start, end + 1):\n",
    "            pbar.set_description(f\"ğŸ“– {section.capitalize()} - Page {page_num}\")\n",
    "            \n",
    "            text = extract_text(pdf_path, page_num)\n",
    "            if not text or len(text) < 10:\n",
    "                pbar.write(f\"âš ï¸  Page {page_num}: No text\")\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "            \n",
    "            start_time = time.time()\n",
    "            result = backend.translate(text, source_lang=SOURCE_LANG, target_lang=TARGET_LANG)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            results.append({\n",
    "                'page_num': page_num,\n",
    "                'section': section,\n",
    "                'original': text,\n",
    "                'translation': result['translation'],\n",
    "                'time': elapsed\n",
    "            })\n",
    "            \n",
    "            pbar.write(f\"âœ… Page {page_num}: {elapsed:.2f}s\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… Translation Complete!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ğŸ“Š Pages: {len(results)}\")\n",
    "total_time = sum(r['time'] for r in results)\n",
    "print(f\"â±ï¸  Total: {total_time:.1f}s\")\n",
    "print(f\"âš¡ Avg: {total_time/len(results):.1f}s/page\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: é¡¯ç¤ºçµæœ\n",
    "\n",
    "**æŸ¥çœ‹ç¿»è­¯**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“„ Page 1 - ABSTRACT\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Original:\n",
      "--------------------------------------------------------------------------------\n",
      "2024-02-21\n",
      "Gemma: Open Models Based on Gemini\n",
      "Research and Technology\n",
      "Gemma Team, Google DeepMind1\n",
      "This work introduces Gemma, a family of lightweight, state-of-the art open models built from the research\n",
      "and technology used to create Gemini models. Gemma models demonstrate strong performance across...\n",
      "\n",
      "ğŸŒ Translation:\n",
      "--------------------------------------------------------------------------------\n",
      "è«–æ–‡æ‘˜è¦ï¼š\n",
      "Gemma æ˜¯ä¸€ç³»åˆ—åŸºäº Gemini çš„è½»é‡çº§ã€å…ˆè¿›çš„å¼€æºæ¨¡å‹ã€‚è¿™äº›æ¨¡å‹åœ¨è¯­è¨€ç†è§£ã€æ¨ç†å’Œå®‰å…¨æ€§ç­‰æ–¹é¢çš„è¡¨ç°ä¼˜å¼‚ã€‚æˆ‘ä»¬å‘å¸ƒäº†ä¸¤ä¸ªä¸åŒå¤§å°çš„æ¨¡å‹ï¼ˆ70 äº¿å’Œ 20 äº¿å‚æ•°ï¼‰ï¼Œå¹¶æä¾›äº†é¢„è®­ç»ƒå’Œå¾®è°ƒçš„æ£€æŸ¥ç‚¹ã€‚Gemma åœ¨ 18 é¡¹åŸºäºæ–‡æœ¬çš„ä»»åŠ¡ä¸­ï¼Œä¼˜äºåŒç­‰è§„æ¨¡çš„å¼€æºæ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†æ¨¡å‹å®‰å…¨æ€§å’Œè´£ä»»æ–¹é¢çš„å…¨é¢è¯„ä¼°ï¼Œä»¥åŠè¯¦ç»†çš„æ¨¡å‹å¼€å‘æè¿°ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œè´Ÿè´£ä»»åœ°å‘å¸ƒå¤§å‹è¯­è¨€æ¨¡å‹å¯¹äºæé«˜å‰æ²¿æ¨¡å‹çš„å®‰å…¨æ€§ï¼Œä»¥åŠä¿ƒè¿›ä¸‹ä¸€ä»£å¤§å‹è¯­è¨€æ¨¡å‹åˆ›æ–°çš„å…³é”®ã€‚\n",
      "\n",
      "â±ï¸  187.38s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for r in results:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"ğŸ“„ Page {r['page_num']} - {r['section'].upper()}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nğŸ“ Original:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(r['original'][:300] + \"...\" if len(r['original']) > 300 else r['original'])\n",
    "    \n",
    "    print(\"\\nğŸŒ Translation:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(r['translation'][:300] + \"...\" if len(r['translation']) > 300 else r['translation'])\n",
    "    \n",
    "    print(f\"\\nâ±ï¸  {r['time']:.2f}s\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: ç”Ÿæˆ HTML\n",
    "\n",
    "**ğŸ’¾ å„²å­˜äº’å‹•å¼ç¶²é **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if SAVE_HTML:\n    from datetime import datetime\n    import os\n    \n    # Generate HTML (simplified version)\n    pages_html = \"\"\n    for idx, r in enumerate(results):\n        display_style = \"\" if idx == 0 else 'style=\"display: none;\"'\n        pages_html += f\"\"\"\n        <div id=\"page-{idx}\" class=\"page\" {display_style}>\n            <div class=\"header\">\n                <h2>ğŸ“„ {r['section'].upper()} - Page {r['page_num']}</h2>\n                <span>â±ï¸ {r['time']:.2f}s</span>\n            </div>\n            <div class=\"columns\">\n                <div class=\"col\"><h3>Original</h3><pre>{r['original']}</pre></div>\n                <div class=\"col\"><h3>Translation</h3><pre>{r['translation']}</pre></div>\n            </div>\n        </div>\n        \"\"\"\n    \n    html = f\"\"\"\n    <!DOCTYPE html>\n    <html>\n    <head>\n        <meta charset=\"UTF-8\">\n        <title>arXiv:{ARXIV_ID} - TranslateGemma</title>\n        <style>\n            body {{ font-family: sans-serif; max-width: 1400px; margin: 0 auto; padding: 20px; background: #f5f5f5; }}\n            h1 {{ text-align: center; color: #667eea; }}\n            .nav {{ position: sticky; top: 0; background: white; padding: 15px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);\n                    display: flex; justify-content: space-between; margin-bottom: 20px; border-radius: 8px; }}\n            button {{ padding: 10px 20px; background: #667eea; color: white; border: none; border-radius: 4px; cursor: pointer; }}\n            button:disabled {{ opacity: 0.5; }}\n            .page {{ background: white; margin: 20px 0; border-radius: 8px; overflow: hidden; }}\n            .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 15px 20px;\n                       display: flex; justify-content: space-between; }}\n            .columns {{ display: grid; grid-template-columns: 1fr 1fr; gap: 0; }}\n            .col {{ padding: 20px; }}\n            .col:first-child {{ background: #f8f9fa; border-right: 2px solid #ddd; }}\n            pre {{ white-space: pre-wrap; line-height: 1.8; margin: 0; }}\n        </style>\n        <script>\n            let c=0,t={len(results)},p={[r['page_num'] for r in results]};\n            function show(i){{if(i<0||i>=t)return;document.querySelectorAll('.page').forEach(p=>p.style.display='none');\n            document.getElementById('page-'+i).style.display='block';c=i;update();window.scrollTo({{top:0}});}}\n            function update(){{document.getElementById('prev').disabled=(c===0);\n            document.getElementById('next').disabled=(c===t-1);\n            document.getElementById('info').textContent=`Page ${{p[c]}} (${{c+1}}/${{t}})`;}}\n            document.addEventListener('keydown',e=>{{if(e.key==='ArrowLeft')show(c-1);if(e.key==='ArrowRight')show(c+1);}});\n            window.onload=update;\n        </script>\n    </head>\n    <body>\n        <h1>ğŸ“„ arXiv:{ARXIV_ID} Bilingual Translation</h1>\n        <p style=\"text-align: center; color: #666;\">{SOURCE_LANG} â†’ {TARGET_LANG} | {datetime.now().strftime(\"%Y-%m-%d %H:%M\")}</p>\n        <div class=\"nav\">\n            <button id=\"prev\" onclick=\"show(c-1)\">â—€ Prev</button>\n            <span id=\"info\"></span>\n            <button id=\"next\" onclick=\"show(c+1)\">Next â–¶</button>\n        </div>\n        <p style=\"text-align: center; background: #fff3cd; padding: 10px; border-radius: 4px;\">ğŸ’¡ Use â† â†’ keys</p>\n        {pages_html}\n    </body>\n    </html>\n    \"\"\"\n    \n    filename = f\"arxiv_{ARXIV_ID}_{SOURCE_LANG}-{TARGET_LANG}.html\"\n    filepath = os.path.abspath(filename)\n    \n    # Save HTML file\n    with open(filename, 'w', encoding='utf-8') as f:\n        f.write(html)\n    \n    print(f\"ğŸ’¾ HTML saved: {filename}\")\n    print(f\"ğŸ“‚ Full path: {filepath}\")\n    print(f\"ğŸ“Š Size: {os.path.getsize(filename) / 1024:.1f} KB\")\n    print(f\"ğŸ“„ Pages: {len(results)}\")\n    \n    # Show preview of first translation\n    print(f\"\\nğŸ” Preview (first 200 chars):\")\n    print(\"-\" * 80)\n    first_translation = results[0]['translation'][:200]\n    print(first_translation + \"...\" if len(results[0]['translation']) > 200 else first_translation)\n    print(\"-\" * 80)\n    \n    print(f\"\\nğŸ“¥ To view the full HTML:\")\n    print(f\"   1. Download: Right-click '{filename}' in Files panel â†’ Download\")\n    print(f\"   2. Or use path: {filepath}\")\n    \n    # Try auto-download for native Colab (fails gracefully if remote)\n    if ENV == 'colab':\n        try:\n            from google.colab import files\n            files.download(filename)\n            print(f\"\\nâœ… Auto-download triggered (native Colab only)\")\n        except Exception as e:\n            print(f\"\\nğŸ’¡ For VSCode remote access:\")\n            print(f\"   â†’ Open Files panel (left sidebar)\")\n            print(f\"   â†’ Find '{filename}'\")\n            print(f\"   â†’ Right-click â†’ Download\")\nelse:\n    print(\"â­ï¸  HTML generation skipped\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ å®Œæˆï¼\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "1. **ç¿»è­¯å…¶ä»–è«–æ–‡**: ä¿®æ”¹ Step 5 çš„ `ARXIV_ID`\n",
    "2. **æŸ¥çœ‹ HTML**: åœ¨ç€è¦½å™¨é–‹å•Ÿä¸‹è¼‰çš„æª”æ¡ˆ\n",
    "3. **åˆ†äº«**: æ­¡è¿åˆ†äº«åˆ°ç¤¾ç¾¤åª’é«” ğŸš€\n",
    "\n",
    "### ç›¸é—œé€£çµ\n",
    "\n",
    "- [GitHub](https://github.com/jimmyliao/trans-gemma)\n",
    "- [TranslateGemma Paper](https://arxiv.org/abs/2601.09012)\n",
    "- [Gemma Model](https://huggingface.co/google/gemma-2-2b-it)\n",
    "\n",
    "**Made with â¤ï¸ by Jimmy Liao**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}