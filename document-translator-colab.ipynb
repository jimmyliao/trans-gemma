{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# TranslateGemma - Document Translator\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jimmyliao/trans-gemma/blob/main/document-translator-colab.ipynb)\n\nTranslate PDFs and images to Traditional Chinese (zh-TW) using Google's TranslateGemma model.\n\n**Features:**\n- üìÑ Download from arXiv automatically\n- üñºÔ∏è Upload images or PDFs\n- üöÄ Fast GPU inference on Colab (T4)\n- üáπüáº Force Traditional Chinese output (configurable)\n\n**Single Source of Truth:** Uses the same code from [trans-gemma repo](https://github.com/jimmyliao/trans-gemma)\n\n---\n\n## üë§ About the Author\n\n**Jimmy Liao** - AI GDE (Google Developer Expert), CTO/Co-Founder of AI Startup\n\nDedicated to smart manufacturing and finance sectors, focusing on transforming technical challenges from AI advancement into competitive advantages while enhancing client value and operational efficiency.\n\n- üê¶ Twitter: [@jimmyliao](https://twitter.com/jimmyliao)\n- üíº LinkedIn: [jimmyliao](https://linkedin.com/in/jimmyliao)\n- üìù Blog: [memo.jimmyliao.net](https://memo.jimmyliao.net)\n- üîó Sessionize: [jimmy-liao](https://sessionize.com/jimmy-liao/)\n\n---\n\n**Disclaimer:** This notebook is provided for educational and research purposes. The author is not affiliated with Google's TranslateGemma team. Use at your own discretion."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (single source of truth)\n",
    "!git clone https://github.com/jimmyliao/trans-gemma.git\n",
    "%cd trans-gemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv (fast Python package manager)\n",
    "!pip install uv -q\n",
    "\n",
    "# Install project dependencies\n",
    "!uv pip install --system -e \".[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 2.5Ô∏è‚É£ HuggingFace Authentication\n\n**IMPORTANT:** TranslateGemma is a gated model. You need to:\n1. Get a HuggingFace token from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n2. Accept model access at [https://huggingface.co/google/translategemma-4b-it](https://huggingface.co/google/translategemma-4b-it)\n3. Add your token to Colab Secrets (üîë icon on left sidebar, name: `HF_TOKEN`)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from huggingface_hub import login\nimport os\n\ntry:\n    # Try to load from Colab secrets (recommended)\n    from google.colab import userdata\n    HF_TOKEN = userdata.get('HF_TOKEN')\n    os.environ['HF_TOKEN'] = HF_TOKEN\n    login(token=HF_TOKEN)\n    print(\"‚úÖ Authenticated with HuggingFace using Colab secrets\")\nexcept Exception as e:\n    print(\"‚ö†Ô∏è  Could not load HF_TOKEN from Colab secrets\")\n    print(\"Please add HF_TOKEN to Colab Secrets (üîë icon on left sidebar)\")\n    print(f\"Error: {e}\")\n    \n    # Fallback: Manual token input\n    print(\"\\nüìù Or enter your token manually:\")\n    HF_TOKEN = input(\"HuggingFace Token: \")\n    os.environ['HF_TOKEN'] = HF_TOKEN\n    login(token=HF_TOKEN)\n    print(\"‚úÖ Authenticated with HuggingFace\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3Ô∏è‚É£ Configuration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# Target language (default: Traditional Chinese)\nTARGET_LANG = \"zh-TW\"  # Change to \"zh-CN\", \"ja\", \"ko\", etc. if needed\n\n# Backend (transformers is best for Colab GPU)\nBACKEND = \"transformers\"\n\nprint(f\"‚úÖ Target language: {TARGET_LANG}\")\nprint(f\"‚úÖ Backend: {BACKEND}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Option A: Download from arXiv\n",
    "\n",
    "Automatically download and translate arXiv papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter arXiv ID (e.g., \"2601.09012v2\" or \"2601.09012\")\n",
    "ARXIV_ID = \"2601.09012v2\"  # TranslateGemma technical report\n",
    "\n",
    "# Translate specific pages (1-indexed)\n",
    "START_PAGE = 1\n",
    "END_PAGE = 1  # Set to None for all pages\n",
    "\n",
    "# Build command\n",
    "cmd = f\"python examples/translate.py --mode pdf --arxiv {ARXIV_ID} --backend {BACKEND} --target {TARGET_LANG}\"\n",
    "if START_PAGE:\n",
    "    cmd += f\" --start-page {START_PAGE}\"\n",
    "if END_PAGE:\n",
    "    cmd += f\" --end-page {END_PAGE}\"\n",
    "\n",
    "print(f\"Running: {cmd}\\n\")\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Option B: Upload PDF\n",
    "\n",
    "Upload your own PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Upload PDF\n",
    "print(\"üì§ Please upload your PDF file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get uploaded filename\n",
    "pdf_file = list(uploaded.keys())[0]\n",
    "print(f\"\\n‚úÖ Uploaded: {pdf_file}\")\n",
    "\n",
    "# Translate\n",
    "START_PAGE = 1\n",
    "END_PAGE = 3  # Change as needed\n",
    "\n",
    "cmd = f\"python examples/translate.py --mode pdf --file {pdf_file} --backend {BACKEND} --target {TARGET_LANG}\"\n",
    "if START_PAGE:\n",
    "    cmd += f\" --start-page {START_PAGE}\"\n",
    "if END_PAGE:\n",
    "    cmd += f\" --end-page {END_PAGE}\"\n",
    "\n",
    "print(f\"\\nRunning: {cmd}\\n\")\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Option C: PDF with Image Mode (Multimodal)\n",
    "\n",
    "Use multimodal TranslateGemma to preserve visual context (tables, charts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For arXiv\n",
    "ARXIV_ID = \"2601.09012v2\"\n",
    "START_PAGE = 1\n",
    "END_PAGE = 1\n",
    "DPI = 96  # Lower DPI = faster (72, 96, or 150)\n",
    "\n",
    "cmd = f\"python examples/translate.py --mode pdf --arxiv {ARXIV_ID} --backend {BACKEND} --target {TARGET_LANG} --pdf-as-image --dpi {DPI}\"\n",
    "if START_PAGE:\n",
    "    cmd += f\" --start-page {START_PAGE}\"\n",
    "if END_PAGE:\n",
    "    cmd += f\" --end-page {END_PAGE}\"\n",
    "\n",
    "print(f\"Running: {cmd}\\n\")\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Single Image Translation\n",
    "\n",
    "Upload and translate a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.insert(0, 'examples')\n",
    "\n",
    "# Upload image\n",
    "print(\"üì§ Please upload your image:\")\n",
    "uploaded = files.upload()\n",
    "image_file = list(uploaded.keys())[0]\n",
    "\n",
    "# Load backend\n",
    "from backends import TransformersMultimodalBackend\n",
    "\n",
    "print(\"\\nüîÑ Loading multimodal backend...\")\n",
    "backend = TransformersMultimodalBackend()\n",
    "backend.load_model()\n",
    "\n",
    "# Translate\n",
    "print(f\"\\nüîÑ Translating {image_file}...\")\n",
    "result = backend.translate_image(image_file, source_lang=\"en\", target_lang=TARGET_LANG)\n",
    "\n",
    "# Display result\n",
    "print(f\"\\n‚úÖ Translation:\")\n",
    "print(result['translation'])\n",
    "print(f\"\\n‚è±Ô∏è  Time: {result['time']:.2f}s, Speed: {result['metadata']['tokens_per_second']:.1f} tok/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Notes\n",
    "\n",
    "- **Backend**: `transformers` is best for Colab GPU (T4)\n",
    "- **Target Language**: Default is `zh-TW` (Traditional Chinese), change in Configuration section\n",
    "- **Image Mode**: Slower but preserves visual context (tables, charts, layout)\n",
    "- **DPI**: Lower DPI (72-96) is faster, higher DPI (150) has better quality\n",
    "\n",
    "## üîó Links\n",
    "\n",
    "- [GitHub Repository](https://github.com/jimmyliao/trans-gemma)\n",
    "- [TranslateGemma Model](https://huggingface.co/google/translategemma-4b-it)\n",
    "- [Documentation](https://github.com/jimmyliao/trans-gemma/blob/main/examples/README.md)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}