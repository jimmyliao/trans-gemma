{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35679da7-c8af-4e17-b9d3-a8e1166dd4c9"
      },
      "source": [
        "# TranslateGemma - Document Translator\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jimmyliao/trans-gemma/blob/main/document-translator-colab.ipynb)\n",
        "\n",
        "Translate PDFs, images, and websites to Traditional Chinese (zh-TW) using Google's TranslateGemma model.\n",
        "\n",
        "**Features:**\n",
        "- üìÑ Download from arXiv automatically\n",
        "- üñºÔ∏è Upload images or PDFs\n",
        "- üåê Screenshot websites and translate\n",
        "- üöÄ Fast GPU inference on Colab (T4)\n",
        "- üáπüáº Force Traditional Chinese output (configurable)\n",
        "\n",
        "**Single Source of Truth:** Uses the same code from [trans-gemma repo](https://github.com/jimmyliao/trans-gemma)\n",
        "\n",
        "---\n",
        "\n",
        "## üë§ About the Author\n",
        "\n",
        "**Jimmy Liao** - AI GDE (Google Developer Expert), CTO/Co-Founder of AI Startup\n",
        "\n",
        "Dedicated to smart manufacturing and finance sectors, focusing on transforming technical challenges from AI advancement into competitive advantages while enhancing client value and operational efficiency.\n",
        "\n",
        "- üê¶ Twitter: [@jimmyliao](https://twitter.com/jimmyliao)\n",
        "- üíº LinkedIn: [jimmyliao](https://linkedin.com/in/jimmyliao)\n",
        "- üìù Blog: [memo.jimmyliao.net](https://memo.jimmyliao.net)\n",
        "- üîó Sessionize: [jimmy-liao](https://sessionize.com/jimmy-liao/)\n",
        "\n",
        "---\n",
        "\n",
        "**Disclaimer:** This notebook is provided for educational and research purposes. The author is not affiliated with Google's TranslateGemma team. Use at your own discretion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dd0d5a8-b32c-4d7d-b1ea-4950bea47310"
      },
      "source": [
        "## 1Ô∏è‚É£ Setup: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5000820-8c17-4210-81fa-80c42412b6e8"
      },
      "outputs": [],
      "source": [
        "# Clean up existing directory if it exists\n",
        "!rm -rf trans-gemma\n",
        "\n",
        "# Clone the repository (single source of truth)\n",
        "!git clone https://github.com/jimmyliao/trans-gemma.git\n",
        "%cd trans-gemma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "523592cb-8207-4010-ae76-40e026fc7624"
      },
      "source": [
        "## 2Ô∏è‚É£ Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1978e099-63b3-4137-8650-af8c3ebcdf32"
      },
      "outputs": [],
      "source": [
        "# Install uv (fast Python package manager)\n",
        "!pip install uv -q\n",
        "\n",
        "# Install project dependencies\n",
        "!uv pip install --system -e \".[examples]\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5Ô∏è‚É£ HuggingFace Authentication\n",
        "\n",
        "**IMPORTANT:** TranslateGemma is a gated model. You need to:\n",
        "1. Get a HuggingFace token from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
        "2. Accept model access at [https://huggingface.co/google/translategemma-4b-it](https://huggingface.co/google/translategemma-4b-it)\n",
        "\n",
        "### üîê Configuration Methods (Choose ONE based on your environment)\n",
        "\n",
        "#### **Option A: Web Colab** (Using browser)\n",
        "1. Click the üîë icon on left sidebar\n",
        "2. Add secret: `HF_TOKEN` = your token\n",
        "3. Run the cell below ‚Üí Token loaded automatically from Colab Secrets\n",
        "\n",
        "#### **Option B: VS Code Colab Extension** (Using VS Code locally)\n",
        "\n",
        "**‚ö†Ô∏è Important:** Your local `.env` file is NOT automatically synced to remote Colab runtime!\n",
        "\n",
        "**Solution: Create .env in remote runtime**\n",
        "\n",
        "The cell below will:\n",
        "1. First check if `.env` exists in remote runtime\n",
        "2. If not found, prompt you to enter token\n",
        "3. Automatically create `.env` file in remote runtime\n",
        "4. Use this token for authentication\n",
        "\n",
        "This way, you only need to enter your token once per runtime session.\n",
        "\n",
        "#### **Option C: Manual Input Every Time** (Not recommended)\n",
        "Skip .env creation and enter token manually each time.\n",
        "\n",
        "---\n",
        "\n",
        "**What happens when you run the cell below?**\n",
        "1. Checks for `.env` in current directory (remote runtime)\n",
        "2. If not found, prompts for token and creates `.env`\n",
        "3. If found, reads token from `.env`\n",
        "4. Authenticates with HuggingFace\n",
        ""
      ],
      "metadata": {
        "id": "273f71f2-e5b8-43a2-9f68-6714f155f397"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def get_hf_token():\n",
        "    \"\"\"Smart HF Token retrieval with .env creation for VS Code\"\"\"\n",
        "    \n",
        "    # Method 1: Try .env file in current directory\n",
        "    env_file = Path('.env')\n",
        "    \n",
        "    if env_file.exists():\n",
        "        try:\n",
        "            with open('.env', 'r') as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line.startswith('HF_TOKEN='):\n",
        "                        token = line.split('=', 1)[1].strip().strip('\"').strip(\"'\")\n",
        "                        if token:\n",
        "                            print(\"‚úÖ HF_TOKEN loaded from .env file\")\n",
        "                            return token\n",
        "            print(\"‚ö†Ô∏è  .env file found but HF_TOKEN not set correctly\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Error reading .env: {e}\")\n",
        "    \n",
        "    # Method 2: Try environment variables\n",
        "    token = os.getenv('HF_TOKEN') or os.getenv('HUGGING_FACE_HUB_TOKEN')\n",
        "    if token:\n",
        "        print(\"‚úÖ HF_TOKEN loaded from environment variable\")\n",
        "        return token\n",
        "    \n",
        "    # Method 3: Try Colab Secrets (Web Colab only)\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        token = userdata.get('HF_TOKEN')\n",
        "        print(\"‚úÖ HF_TOKEN loaded from Colab Secrets (Web Colab)\")\n",
        "        return token\n",
        "    except Exception:\n",
        "        pass\n",
        "    \n",
        "    # Method 4: Prompt for token and create .env (VS Code friendly)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"‚ö†Ô∏è  HF_TOKEN not found - Creating .env file\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nüìù Please enter your HuggingFace token:\")\n",
        "    print(\"   Get token: https://huggingface.co/settings/tokens\")\n",
        "    print(\"   Accept access: https://huggingface.co/google/translategemma-4b-it\")\n",
        "    print(\"\\nüí° Your token will be saved to .env for this runtime session\")\n",
        "    print()\n",
        "    \n",
        "    token = input(\"HuggingFace Token: \").strip()\n",
        "    \n",
        "    if token:\n",
        "        # Save to .env for future use in this session\n",
        "        try:\n",
        "            with open('.env', 'w') as f:\n",
        "                f.write(f\"HF_TOKEN={token}\\n\")\n",
        "            print(\"\\n‚úÖ Token saved to .env file (runtime session)\")\n",
        "            print(\"   Next time you run this cell, it will load automatically\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ö†Ô∏è  Could not save to .env: {e}\")\n",
        "            print(\"   Token will work this time but won't persist\")\n",
        "        \n",
        "        return token\n",
        "    else:\n",
        "        raise ValueError(\"‚ùå HF_TOKEN is required to use TranslateGemma\")\n",
        "\n",
        "# Authenticate\n",
        "try:\n",
        "    HF_TOKEN = get_hf_token()\n",
        "    os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"\\n‚úÖ Successfully authenticated with HuggingFace\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Authentication failed: {e}\\n\")\n",
        "    raise"
      ],
      "metadata": {
        "id": "8c04d29b-246d-4b99-bbc8-2b8001deb172"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Configuration"
      ],
      "metadata": {
        "id": "070fce79-95e5-4145-96e9-6851e545f959"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "992be9b9-04ec-4018-8179-d609d5f80950"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Target language (default: Traditional Chinese)\n",
        "TARGET_LANG = \"zh-TW\"  # Change to \"zh-CN\", \"ja\", \"ko\", etc. if needed\n",
        "\n",
        "# Backend (transformers is best for Colab GPU)\n",
        "BACKEND = \"transformers\"\n",
        "\n",
        "print(f\"‚úÖ Target language: {TARGET_LANG}\")\n",
        "print(f\"‚úÖ Backend: {BACKEND}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a36be99-6b11-479a-937b-f5567e228bb3"
      },
      "source": [
        "## 4Ô∏è‚É£ Option A: Download from arXiv\n",
        "\n",
        "Automatically download and translate arXiv papers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9d22680-b468-46d6-a14a-ed28da4427b7"
      },
      "outputs": [],
      "source": [
        "# Enter arXiv ID (e.g., \"2601.09012v2\" or \"2601.09012\")\n",
        "ARXIV_ID = \"2601.09012v2\"  # TranslateGemma technical report\n",
        "\n",
        "# Translate specific pages (1-indexed)\n",
        "START_PAGE = 1\n",
        "END_PAGE = 1  # Set to None for all pages\n",
        "\n",
        "# Build command\n",
        "cmd = f\"python examples/translate.py --mode pdf --arxiv {ARXIV_ID} --backend {BACKEND} --target {TARGET_LANG}\"\n",
        "if START_PAGE:\n",
        "    cmd += f\" --start-page {START_PAGE}\"\n",
        "if END_PAGE:\n",
        "    cmd += f\" --end-page {END_PAGE}\"\n",
        "\n",
        "print(f\"Running: {cmd}\\n\")\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cd2c6a1-52e5-4162-ba5d-cb892a5ffabc"
      },
      "source": [
        "## 4Ô∏è‚É£ Option B: Upload PDF\n",
        "\n",
        "Upload your own PDF file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beca7a16-805d-4354-9e7f-6810b37fb04c"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Upload PDF\n",
        "print(\"üì§ Please upload your PDF file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get uploaded filename\n",
        "pdf_file = list(uploaded.keys())[0]\n",
        "print(f\"\\n‚úÖ Uploaded: {pdf_file}\")\n",
        "\n",
        "# Translate settings\n",
        "START_PAGE = 1\n",
        "END_PAGE = 3  # Change as needed\n",
        "USE_IMAGE_MODE = False  # Set to True for multimodal (slower but preserves layout)\n",
        "DPI = 96  # For image mode: lower = faster (72, 96, or 150)\n",
        "\n",
        "# Build command\n",
        "cmd = f\"python examples/translate.py --mode pdf --file {pdf_file} --backend {BACKEND} --target {TARGET_LANG}\"\n",
        "if START_PAGE:\n",
        "    cmd += f\" --start-page {START_PAGE}\"\n",
        "if END_PAGE:\n",
        "    cmd += f\" --end-page {END_PAGE}\"\n",
        "if USE_IMAGE_MODE:\n",
        "    cmd += f\" --pdf-as-image --dpi {DPI}\"\n",
        "\n",
        "print(f\"\\nRunning: {cmd}\\n\")\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "541d517d-572b-40f9-b42b-36fe37c776c7"
      },
      "source": [
        "## 4Ô∏è‚É£ Option C: PDF with Image Mode (Multimodal)\n",
        "\n",
        "Use multimodal TranslateGemma to preserve visual context (tables, charts)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93ade76d-b8b0-4abb-b2fd-7c583bc6c162"
      },
      "outputs": [],
      "source": [
        "# Translate PDF page with charts/figures (multimodal)\n",
        "ARXIV_ID = \"2601.09012v2\"\n",
        "START_PAGE = 3  # Page with Figure 1 (language distribution charts)\n",
        "END_PAGE = 3\n",
        "DPI = 96  # Lower DPI = faster (72, 96, or 150)\n",
        "\n",
        "cmd = f\"python examples/translate.py --mode pdf --arxiv {ARXIV_ID} --backend {BACKEND} --target {TARGET_LANG} --pdf-as-image --dpi {DPI}\"\n",
        "if START_PAGE:\n",
        "    cmd += f\" --start-page {START_PAGE}\"\n",
        "if END_PAGE:\n",
        "    cmd += f\" --end-page {END_PAGE}\"\n",
        "\n",
        "print(f\"Running: {cmd}\\n\")\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0997ab9d-6bab-4c2b-95d2-6571a7a54b1b"
      },
      "source": [
        "## 5Ô∏è‚É£ Single Image Translation\n",
        "\n",
        "Translate text from a single image using multimodal TranslateGemma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d366aea3-421e-4e68-9896-c92b0edb1582"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import sys\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Add examples directory to path\n",
        "sys.path.insert(0, 'examples')\n",
        "sys.path.insert(0, 'examples/backends')\n",
        "\n",
        "# Configuration: Choose image source\n",
        "USE_DEFAULT_IMAGE = True  # Set to False to upload your own image\n",
        "DEFAULT_IMAGE_URL = \"https://cdn.odigo.net/f91b9c108a1e0cd1117e1c46ee36eeca.jpg\"\n",
        "\n",
        "# Language configuration\n",
        "SOURCE_LANG = \"ja\"  # This is a Japanese menu image\n",
        "\n",
        "# Get image\n",
        "if USE_DEFAULT_IMAGE:\n",
        "    print(f\"üì• Downloading default image from:\\n   {DEFAULT_IMAGE_URL}\\n\")\n",
        "    image_file = \"demo_image.jpg\"\n",
        "    urllib.request.urlretrieve(DEFAULT_IMAGE_URL, image_file)\n",
        "    print(f\"‚úÖ Downloaded: {image_file}\")\n",
        "else:\n",
        "    print(\"üì§ Please upload your image:\")\n",
        "    uploaded = files.upload()\n",
        "    image_file = list(uploaded.keys())[0]\n",
        "    print(f\"\\n‚úÖ Uploaded: {image_file}\")\n",
        "\n",
        "# Load backend\n",
        "from transformers_multimodal_backend import TransformersMultimodalBackend\n",
        "\n",
        "print(\"\\nüîÑ Loading multimodal backend...\")\n",
        "backend = TransformersMultimodalBackend()\n",
        "backend.load_model()\n",
        "\n",
        "# Translate\n",
        "print(f\"\\nüîÑ Translating {image_file}...\")\n",
        "print(f\"Source language: {SOURCE_LANG} ‚Üí Target language: {TARGET_LANG}\")\n",
        "result = backend.translate_image(image_file, source_lang=SOURCE_LANG, target_lang=TARGET_LANG)\n",
        "\n",
        "# Display result\n",
        "print(f\"\\n‚úÖ Translation:\")\n",
        "print(result['translation'])\n",
        "print(f\"\\n‚è±Ô∏è  Time: {result['time']:.2f}s, Speed: {result['metadata']['tokens_per_second']:.1f} tok/s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6Ô∏è‚É£ Website Article Translation (Web Scraping)\n",
        "\n",
        "Extract text from websites and translate them accurately using web scraping instead of screenshots."
      ],
      "metadata": {
        "id": "8a6af8b6-3fb4-40a8-9a7f-cca84488c3b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install web scraping dependencies\n",
        "!pip install beautifulsoup4 requests -q\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import sys\n",
        "import time\n",
        "sys.path.insert(0, 'examples')\n",
        "sys.path.insert(0, 'examples/backends')\n",
        "\n",
        "# Configuration\n",
        "ARTICLE_URL = \"https://aismiley.co.jp/ai_news/gemma3-rag-api-local-use/\"\n",
        "SOURCE_LANG = \"ja\"  # Japanese article\n",
        "\n",
        "def extract_article_text(url):\n",
        "    \"\"\"Extract main article content from webpage\"\"\"\n",
        "    print(f\"üåê Fetching webpage: {url}\\n\")\n",
        "    \n",
        "    # Fetch webpage\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    response.encoding = response.apparent_encoding\n",
        "    \n",
        "    # Parse HTML\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    \n",
        "    # Extract title from h1\n",
        "    title = soup.find('h1')\n",
        "    title_text = title.get_text(strip=True) if title else \"No title found\"\n",
        "    \n",
        "    # Remove unwanted elements (navigation, sidebar, footer, scripts)\n",
        "    for element in soup.select('nav, aside, footer, script, style, .sidebar, .navigation, .menu, .footer, .header'):\n",
        "        element.decompose()\n",
        "    \n",
        "    # Try to find main content area with multiple strategies\n",
        "    content_area = None\n",
        "    \n",
        "    # Strategy 1: Look for specific content containers\n",
        "    content_selectors = [\n",
        "        'main',\n",
        "        'article',\n",
        "        '.main-content',\n",
        "        '.article-content',\n",
        "        '.post-content',\n",
        "        '.entry-content',\n",
        "        '#content',\n",
        "        '.content'\n",
        "    ]\n",
        "    \n",
        "    for selector in content_selectors:\n",
        "        content_area = soup.select_one(selector)\n",
        "        if content_area and len(content_area.find_all('p')) > 3:\n",
        "            print(f\"üìç Found content using selector: {selector}\")\n",
        "            break\n",
        "    \n",
        "    # Strategy 2: If no content area found, look for area with most paragraphs\n",
        "    if not content_area or len(content_area.find_all('p')) < 3:\n",
        "        print(\"üìç Using body and filtering paragraphs by length\")\n",
        "        content_area = soup.find('body')\n",
        "    \n",
        "    # Extract paragraphs and headings\n",
        "    paragraphs = []\n",
        "    seen_texts = set()  # Avoid duplicates\n",
        "    \n",
        "    for element in content_area.find_all(['p', 'h2', 'h3', 'li']):\n",
        "        text = element.get_text(strip=True)\n",
        "        \n",
        "        # Filter conditions\n",
        "        if (len(text) < 15 or  # Too short\n",
        "            text in seen_texts or  # Duplicate\n",
        "            text.lower().startswith(('cookie', 'privacy', 'terms', 'Âà©Áî®Ë¶èÁ¥Ñ', '„Éó„É©„Ç§„Éê„Ç∑„Éº')) or  # Legal text\n",
        "            'href' in text.lower() or  # Likely a link\n",
        "            text.count('|') > 2):  # Navigation menu\n",
        "            continue\n",
        "        \n",
        "        seen_texts.add(text)\n",
        "        paragraphs.append(text)\n",
        "    \n",
        "    print(f\"‚úÖ Extracted {len(paragraphs)} unique paragraphs\")\n",
        "    \n",
        "    # Show first few paragraphs for debugging\n",
        "    if paragraphs:\n",
        "        print(f\"\\nüìã First 3 paragraphs:\")\n",
        "        for i, p in enumerate(paragraphs[:3], 1):\n",
        "            preview = p[:80] + \"...\" if len(p) > 80 else p\n",
        "            print(f\"   {i}. {preview}\")\n",
        "    \n",
        "    # Combine text (limit to first 10 paragraphs to stay within token limits)\n",
        "    # IMPORTANT: Reduced from 20 to 10 paragraphs for better translation quality\n",
        "    full_text = f\"{title_text}\\n\\n\" + \"\\n\\n\".join(paragraphs[:10])\n",
        "    \n",
        "    return {\n",
        "        'title': title_text,\n",
        "        'text': full_text,\n",
        "        'paragraph_count': len(paragraphs),\n",
        "        'paragraphs_used': min(10, len(paragraphs))\n",
        "    }\n",
        "\n",
        "# Extract article\n",
        "print(\"üìÑ Extracting article content...\\n\")\n",
        "article = extract_article_text(ARTICLE_URL)\n",
        "\n",
        "print(f\"\\n‚úÖ Article summary:\")\n",
        "print(f\"   Title: {article['title']}\")\n",
        "print(f\"   Total paragraphs: {article['paragraph_count']}\")\n",
        "print(f\"   Using paragraphs: {article['paragraphs_used']}\")\n",
        "print(f\"   Text length: {len(article['text'])} characters\\n\")\n",
        "\n",
        "# Check if we have enough content\n",
        "if article['paragraph_count'] < 3:\n",
        "    print(\"‚ö†Ô∏è  Warning: Very few paragraphs extracted. The article might not be accessible or requires different extraction logic.\")\n",
        "    print(\"   Proceeding with available content...\\n\")\n",
        "\n",
        "# Load translation backend\n",
        "from transformers_backend import TransformersBackend\n",
        "\n",
        "print(\"üîÑ Loading translation backend...\")\n",
        "backend = TransformersBackend()\n",
        "backend.load_model()\n",
        "\n",
        "# Translate article\n",
        "print(f\"\\nüîÑ Translating article...\")\n",
        "print(f\"Source language: {SOURCE_LANG} ‚Üí Target language: {TARGET_LANG}\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Monkey patch to increase max_new_tokens and add debug output\n",
        "import torch\n",
        "original_translate = backend.translate\n",
        "\n",
        "def translate_with_more_tokens(text, source_lang, target_lang):\n",
        "    \"\"\"Modified translate with more tokens and debug output\"\"\"\n",
        "    # Build structured message\n",
        "    messages = [{\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [{\n",
        "            \"type\": \"text\",\n",
        "            \"text\": text,\n",
        "            \"source_lang_code\": source_lang,\n",
        "            \"target_lang_code\": target_lang\n",
        "        }]\n",
        "    }]\n",
        "\n",
        "    # Apply chat template\n",
        "    inputs = backend.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(backend.model.device)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Generate with MORE tokens\n",
        "    with torch.no_grad():\n",
        "        outputs = backend.model.generate(\n",
        "            inputs,\n",
        "            max_new_tokens=1024,  # Increased from 256 to 1024\n",
        "            do_sample=False\n",
        "        )\n",
        "\n",
        "    duration = time.time() - start\n",
        "\n",
        "    # Decode full output\n",
        "    full_output = backend.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    \n",
        "    # Debug: Show full output\n",
        "    print(\"\\nüîç Debug - Full model output (first 500 chars):\")\n",
        "    print(full_output[:500])\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "    # Extract translation (improved logic)\n",
        "    # Strategy 1: Split by newline and get last non-empty line\n",
        "    lines = [line.strip() for line in full_output.split('\\n') if line.strip()]\n",
        "    translation = lines[-1] if lines else full_output\n",
        "    \n",
        "    # Strategy 2: Remove prompt prefix if present\n",
        "    if ':' in translation and len(translation.split(':', 1)[1].strip()) > 10:\n",
        "        translation = translation.split(':', 1)[1].strip()\n",
        "\n",
        "    # Post-processing: Convert Simplified to Traditional Chinese\n",
        "    if target_lang == \"zh-TW\":\n",
        "        try:\n",
        "            from hanziconv import HanziConv\n",
        "            translation = HanziConv.toTraditional(translation)\n",
        "        except ImportError:\n",
        "            pass\n",
        "\n",
        "    # Calculate tokens\n",
        "    input_tokens = inputs.shape[1]\n",
        "    output_tokens = outputs.shape[1] - input_tokens\n",
        "    total_tokens = outputs.shape[1]\n",
        "\n",
        "    return {\n",
        "        \"translation\": translation,\n",
        "        \"time\": duration,\n",
        "        \"tokens\": total_tokens,\n",
        "        \"metadata\": {\n",
        "            \"input_tokens\": input_tokens,\n",
        "            \"output_tokens\": output_tokens,\n",
        "            \"tokens_per_second\": total_tokens / duration if duration > 0 else 0,\n",
        "            \"full_output_preview\": full_output[:200]\n",
        "        }\n",
        "    }\n",
        "\n",
        "backend.translate = translate_with_more_tokens\n",
        "\n",
        "result = backend.translate(article['text'], source_lang=SOURCE_LANG, target_lang=TARGET_LANG)\n",
        "end_time = time.time()\n",
        "\n",
        "# Display result with word wrap\n",
        "import textwrap\n",
        "\n",
        "print(f\"\\n‚úÖ Translation Result:\")\n",
        "print(\"=\" * 80)\n",
        "wrapped_translation = textwrap.fill(result['translation'], width=80, break_long_words=False, break_on_hyphens=False)\n",
        "print(wrapped_translation)\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è  Time: {result['time']:.2f}s\")\n",
        "print(f\"üìä Speed: {result['metadata']['tokens_per_second']:.1f} tok/s\")\n",
        "print(f\"üî§ Tokens: {result['tokens']} (input: {result['metadata']['input_tokens']}, output: {result['metadata']['output_tokens']})\")"
      ],
      "metadata": {
        "id": "ab51a6c0-4fa5-4ee7-964b-a2c81b5c4119"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7Ô∏è‚É£ Website Screenshot Translation\n\nCapture a screenshot of any website and translate it to Traditional Chinese."
      ],
      "metadata": {
        "id": "946f8b12-28f9-4938-93e5-cb1a92c836c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install system dependencies for Chromium\n",
        "!apt-get update -qq\n",
        "!apt-get install -y -qq libatk1.0-0 libatk-bridge2.0-0 libcups2 libxkbcommon0 libxcomposite1 libxdamage1 libxrandr2 libgbm1 libpango-1.0-0 libcairo2 libasound2\n",
        "\n",
        "# Install Playwright\n",
        "!pip install playwright -q\n",
        "!playwright install chromium --with-deps\n",
        "\n",
        "# Screenshot website and translate\n",
        "import asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "from PIL import Image\n",
        "import sys\n",
        "sys.path.insert(0, 'examples')\n",
        "sys.path.insert(0, 'examples/backends')\n",
        "\n",
        "# Configuration\n",
        "WEBSITE_URL = \"https://www.yomiuri.co.jp/national/20260117-GYT1T00119/\"\n",
        "SOURCE_LANG = \"ja\"  # Japanese news website\n",
        "\n",
        "async def capture_screenshot(url):\n",
        "    \"\"\"Capture website screenshot using Playwright async API\"\"\"\n",
        "    print(f\"üì∏ Capturing screenshot of: {url}\\n\")\n",
        "    \n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        page = await browser.new_page(viewport={'width': 1280, 'height': 1024})\n",
        "        await page.goto(url, wait_until='networkidle')\n",
        "        await page.screenshot(path='website_screenshot.png', full_page=False)\n",
        "        await browser.close()\n",
        "    \n",
        "    print(\"‚úÖ Screenshot saved: website_screenshot.png\\n\")\n",
        "\n",
        "# Capture screenshot\n",
        "await capture_screenshot(WEBSITE_URL)\n",
        "\n",
        "# Load backend\n",
        "from transformers_multimodal_backend import TransformersMultimodalBackend\n",
        "\n",
        "print(\"üîÑ Loading multimodal backend...\")\n",
        "backend = TransformersMultimodalBackend()\n",
        "backend.load_model()\n",
        "\n",
        "# Translate\n",
        "print(f\"\\nüîÑ Translating screenshot...\")\n",
        "print(f\"Source language: {SOURCE_LANG} ‚Üí Target language: {TARGET_LANG}\\n\")\n",
        "result = backend.translate_image('website_screenshot.png', source_lang=SOURCE_LANG, target_lang=TARGET_LANG)\n",
        "\n",
        "# Display result\n",
        "print(f\"\\n‚úÖ Translation:\")\n",
        "print(result['translation'])\n",
        "print(f\"\\n‚è±Ô∏è  Time: {result['time']:.2f}s, Speed: {result['metadata']['tokens_per_second']:.1f} tok/s\")\n",
        "\n",
        "# Display screenshot\n",
        "from IPython.display import Image as IPImage, display\n",
        "display(IPImage('website_screenshot.png', width=800))"
      ],
      "metadata": {
        "id": "6865e765-15d8-431a-8b32-cbff840875c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b25cb87-b45f-4b4b-a576-7d8ba86829ec"
      },
      "source": [
        "## üìù Notes\n",
        "\n",
        "- **Backend**: `transformers` is best for Colab GPU (T4)\n",
        "- **Target Language**: Default is `zh-TW` (Traditional Chinese), change in Configuration section\n",
        "- **Image Mode**: Slower but preserves visual context (tables, charts, layout)\n",
        "- **DPI**: Lower DPI (72-96) is faster, higher DPI (150) has better quality\n",
        "\n",
        "## üîó Links\n",
        "\n",
        "- [GitHub Repository](https://github.com/jimmyliao/trans-gemma)\n",
        "- [TranslateGemma Model](https://huggingface.co/google/translategemma-4b-it)\n",
        "- [Documentation](https://github.com/jimmyliao/trans-gemma/blob/main/examples/README.md)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "document-translator-colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}