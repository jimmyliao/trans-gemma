{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# TranslateGemma - Document Translator\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jimmyliao/trans-gemma/blob/main/document-translator-colab.ipynb)\n\nTranslate PDFs and images to Traditional Chinese (zh-TW) using Google's TranslateGemma model.\n\n**Features:**\n- üìÑ Download from arXiv automatically\n- üñºÔ∏è Upload images or PDFs\n- üöÄ Fast GPU inference on Colab (T4)\n- üáπüáº Force Traditional Chinese output (configurable)\n\n**Single Source of Truth:** Uses the same code from [trans-gemma repo](https://github.com/jimmyliao/trans-gemma)\n\n---\n\n## üë§ About the Author\n\n**Jimmy Liao** - AI GDE (Google Developer Expert), CTO/Co-Founder of AI Startup\n\nDedicated to smart manufacturing and finance sectors, focusing on transforming technical challenges from AI advancement into competitive advantages while enhancing client value and operational efficiency.\n\n- üê¶ Twitter: [@jimmyliao](https://twitter.com/jimmyliao)\n- üíº LinkedIn: [jimmyliao](https://linkedin.com/in/jimmyliao)\n- üìù Blog: [memo.jimmyliao.net](https://memo.jimmyliao.net)\n- üîó Sessionize: [jimmy-liao](https://sessionize.com/jimmy-liao/)\n\n---\n\n**Disclaimer:** This notebook is provided for educational and research purposes. The author is not affiliated with Google's TranslateGemma team. Use at your own discretion."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clean up existing directory if it exists\n!rm -rf trans-gemma\n\n# Clone the repository (single source of truth)\n!git clone https://github.com/jimmyliao/trans-gemma.git\n%cd trans-gemma"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv (fast Python package manager)\n",
    "!pip install uv -q\n",
    "\n",
    "# Install project dependencies\n",
    "!uv pip install --system -e \".[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 2.5Ô∏è‚É£ HuggingFace Authentication\n\n**IMPORTANT:** TranslateGemma is a gated model. You need to:\n1. Get a HuggingFace token from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n2. Accept model access at [https://huggingface.co/google/translategemma-4b-it](https://huggingface.co/google/translategemma-4b-it)\n3. Add your token to Colab Secrets (üîë icon on left sidebar, name: `HF_TOKEN`)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from huggingface_hub import login\nimport os\n\ntry:\n    # Try to load from Colab secrets (recommended)\n    from google.colab import userdata\n    HF_TOKEN = userdata.get('HF_TOKEN')\n    os.environ['HF_TOKEN'] = HF_TOKEN\n    login(token=HF_TOKEN)\n    print(\"‚úÖ Authenticated with HuggingFace using Colab secrets\")\nexcept Exception as e:\n    print(\"‚ö†Ô∏è  Could not load HF_TOKEN from Colab secrets\")\n    print(\"Please add HF_TOKEN to Colab Secrets (üîë icon on left sidebar)\")\n    print(f\"Error: {e}\")\n    \n    # Fallback: Manual token input\n    print(\"\\nüìù Or enter your token manually:\")\n    HF_TOKEN = input(\"HuggingFace Token: \")\n    os.environ['HF_TOKEN'] = HF_TOKEN\n    login(token=HF_TOKEN)\n    print(\"‚úÖ Authenticated with HuggingFace\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3Ô∏è‚É£ Configuration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# Target language (default: Traditional Chinese)\nTARGET_LANG = \"zh-TW\"  # Change to \"zh-CN\", \"ja\", \"ko\", etc. if needed\n\n# Backend (transformers is best for Colab GPU)\nBACKEND = \"transformers\"\n\nprint(f\"‚úÖ Target language: {TARGET_LANG}\")\nprint(f\"‚úÖ Backend: {BACKEND}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Option A: Download from arXiv\n",
    "\n",
    "Automatically download and translate arXiv papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter arXiv ID (e.g., \"2601.09012v2\" or \"2601.09012\")\n",
    "ARXIV_ID = \"2601.09012v2\"  # TranslateGemma technical report\n",
    "\n",
    "# Translate specific pages (1-indexed)\n",
    "START_PAGE = 1\n",
    "END_PAGE = 1  # Set to None for all pages\n",
    "\n",
    "# Build command\n",
    "cmd = f\"python examples/translate.py --mode pdf --arxiv {ARXIV_ID} --backend {BACKEND} --target {TARGET_LANG}\"\n",
    "if START_PAGE:\n",
    "    cmd += f\" --start-page {START_PAGE}\"\n",
    "if END_PAGE:\n",
    "    cmd += f\" --end-page {END_PAGE}\"\n",
    "\n",
    "print(f\"Running: {cmd}\\n\")\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Option B: Upload PDF\n",
    "\n",
    "Upload your own PDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import files\nimport os\n\n# Upload PDF\nprint(\"üì§ Please upload your PDF file:\")\nuploaded = files.upload()\n\n# Get uploaded filename\npdf_file = list(uploaded.keys())[0]\nprint(f\"\\n‚úÖ Uploaded: {pdf_file}\")\n\n# Translate settings\nSTART_PAGE = 1\nEND_PAGE = 3  # Change as needed\nUSE_IMAGE_MODE = False  # Set to True for multimodal (slower but preserves layout)\nDPI = 96  # For image mode: lower = faster (72, 96, or 150)\n\n# Build command\ncmd = f\"python examples/translate.py --mode pdf --file {pdf_file} --backend {BACKEND} --target {TARGET_LANG}\"\nif START_PAGE:\n    cmd += f\" --start-page {START_PAGE}\"\nif END_PAGE:\n    cmd += f\" --end-page {END_PAGE}\"\nif USE_IMAGE_MODE:\n    cmd += f\" --pdf-as-image --dpi {DPI}\"\n\nprint(f\"\\nRunning: {cmd}\\n\")\n!{cmd}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Option C: PDF with Image Mode (Multimodal)\n",
    "\n",
    "Use multimodal TranslateGemma to preserve visual context (tables, charts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Translate PDF page with charts/figures (multimodal)\nARXIV_ID = \"2601.09012v2\"\nSTART_PAGE = 3  # Page with Figure 1 (language distribution charts)\nEND_PAGE = 3\nDPI = 96  # Lower DPI = faster (72, 96, or 150)\n\ncmd = f\"python examples/translate.py --mode pdf --arxiv {ARXIV_ID} --backend {BACKEND} --target {TARGET_LANG} --pdf-as-image --dpi {DPI}\"\nif START_PAGE:\n    cmd += f\" --start-page {START_PAGE}\"\nif END_PAGE:\n    cmd += f\" --end-page {END_PAGE}\"\n\nprint(f\"Running: {cmd}\\n\")\n!{cmd}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5Ô∏è‚É£ Single Image Translation\n\nTranslate text from a single image using multimodal TranslateGemma."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import files\nfrom PIL import Image\nimport sys\nimport urllib.request\nimport os\n\n# Add examples directory to path\nsys.path.insert(0, 'examples')\nsys.path.insert(0, 'examples/backends')\n\n# Configuration: Choose image source\nUSE_DEFAULT_IMAGE = True  # Set to False to upload your own image\nDEFAULT_IMAGE_URL = \"https://cdn.odigo.net/f91b9c108a1e0cd1117e1c46ee36eeca.jpg\"\n\n# Language configuration\nSOURCE_LANG = \"ja\"  # This is a Japanese menu image\n\n# Get image\nif USE_DEFAULT_IMAGE:\n    print(f\"üì• Downloading default image from:\\n   {DEFAULT_IMAGE_URL}\\n\")\n    image_file = \"demo_image.jpg\"\n    urllib.request.urlretrieve(DEFAULT_IMAGE_URL, image_file)\n    print(f\"‚úÖ Downloaded: {image_file}\")\nelse:\n    print(\"üì§ Please upload your image:\")\n    uploaded = files.upload()\n    image_file = list(uploaded.keys())[0]\n    print(f\"\\n‚úÖ Uploaded: {image_file}\")\n\n# Load backend\nfrom transformers_multimodal_backend import TransformersMultimodalBackend\n\nprint(\"\\nüîÑ Loading multimodal backend...\")\nbackend = TransformersMultimodalBackend()\nbackend.load_model()\n\n# Translate\nprint(f\"\\nüîÑ Translating {image_file}...\")\nprint(f\"Source language: {SOURCE_LANG} ‚Üí Target language: {TARGET_LANG}\")\nresult = backend.translate_image(image_file, source_lang=SOURCE_LANG, target_lang=TARGET_LANG)\n\n# Display result\nprint(f\"\\n‚úÖ Translation:\")\nprint(result['translation'])\nprint(f\"\\n‚è±Ô∏è  Time: {result['time']:.2f}s, Speed: {result['metadata']['tokens_per_second']:.1f} tok/s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Notes\n",
    "\n",
    "- **Backend**: `transformers` is best for Colab GPU (T4)\n",
    "- **Target Language**: Default is `zh-TW` (Traditional Chinese), change in Configuration section\n",
    "- **Image Mode**: Slower but preserves visual context (tables, charts, layout)\n",
    "- **DPI**: Lower DPI (72-96) is faster, higher DPI (150) has better quality\n",
    "\n",
    "## üîó Links\n",
    "\n",
    "- [GitHub Repository](https://github.com/jimmyliao/trans-gemma)\n",
    "- [TranslateGemma Model](https://huggingface.co/google/translategemma-4b-it)\n",
    "- [Documentation](https://github.com/jimmyliao/trans-gemma/blob/main/examples/README.md)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}