{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59d71194-8896-46c3-8e71-ce134896da90"
      },
      "source": [
        "# arXiv Bilingual Reader - TranslateGemma\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jimmyliao/trans-gemma/blob/main/arxiv-reader-colab.ipynb)\n",
        "\n",
        "**å°ˆæ³¨æ–¼é›™èªé–±è®€å­¸ç¿’çš„ arXiv è«–æ–‡ç¿»è­¯å·¥å…·**\n",
        "\n",
        "## ğŸ¯ æ ¸å¿ƒç‰¹è‰²\n",
        "\n",
        "- ğŸ“– **é›™èªå°ç…§é–±è®€**ï¼šåŸæ–‡èˆ‡ç¿»è­¯ä¸¦åˆ—ï¼Œå­¸ç¿’è‹±æ–‡å­¸è¡“å¯«ä½œ\n",
        "- ğŸ§  **æ™ºæ…§æ··åˆæ¨¡å¼**ï¼šç´”æ–‡å­—é é¢å¿«é€Ÿç¿»è­¯ï¼Œå«åœ–è¡¨é é¢ä¿ç•™è¦–è¦ºä¸Šä¸‹æ–‡\n",
        "- ğŸ“š **åˆ†ç« ç¯€ç¿»è­¯**ï¼šæŒ‰è«–æ–‡çµæ§‹ï¼ˆAbstract, Method, Experimentsï¼‰çµ„ç¹”\n",
        "- ğŸ’¡ **è¡“èªå°ç…§è¡¨**ï¼šè‡ªå‹•æå–å°ˆæ¥­è¡“èªï¼Œå»ºç«‹ä¸­è‹±å°ç…§\n",
        "- ğŸ‡¹ğŸ‡¼ **ç¹é«”ä¸­æ–‡å„ªåŒ–**ï¼šç¢ºä¿è¼¸å‡ºå°ç£æ…£ç”¨çš„ç¹é«”ä¸­æ–‡ï¼ˆå·²ä¿®å¾©å®˜æ–¹ bugï¼‰\n",
        "\n",
        "## ğŸ“ é©åˆèª°ä½¿ç”¨ï¼Ÿ\n",
        "\n",
        "- âœ… ç ”ç©¶ç”Ÿå­¸ç¿’é–±è®€è‹±æ–‡è«–æ–‡\n",
        "- âœ… ç ”ç©¶è€…æ·±å…¥ç ”è®€é‡è¦æ–‡ç»\n",
        "- âœ… æº–å‚™è«–æ–‡å¯«ä½œ/å¯©ç¨¿çš„å­¸è€…\n",
        "- âœ… æƒ³å­¸ç¿’è‹±æ–‡å­¸è¡“å¯«ä½œçš„äºº\n",
        "\n",
        "## âš¡ å¿«é€Ÿé–‹å§‹\n",
        "\n",
        "1. åŸ·è¡Œ Cell 1-2ï¼ˆç’°å¢ƒè¨­ç½® + èªè­‰ï¼‰\n",
        "2. åœ¨ Cell 3 è¼¸å…¥ arXiv è«–æ–‡ ID å’Œè¨­å®š\n",
        "3. åŸ·è¡Œ Cell 4 é–‹å§‹ç¿»è­¯\n",
        "4. äº«å—é›™èªå°ç…§é–±è®€ï¼\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‘¤ About the Author\n",
        "\n",
        "<div style=\"display: flex; align-items: center; gap: 20px; margin: 20px 0;\">\n",
        "  <img src=\"https://sessionize.com/image/5591-400o400o2-BnJLo7cscQKXC1GqE7bFcw.jpg\" alt=\"Jimmy Liao\" style=\"width: 100px; height: 100px; border-radius: 50%; object-fit: cover;\">\n",
        "  <div>\n",
        "    <strong style=\"font-size: 1.2em;\">Jimmy Liao</strong><br>\n",
        "    <span style=\"color: #666;\">AI GDE/MVP, CTO of AI Startup</span>\n",
        "  </div>\n",
        "</div>\n",
        "\n",
        "\n",
        "\n",
        "- ğŸ¦ Twitter: [@jimmyliao](https://twitter.com/jimmyliao)\n",
        "- ğŸ’¼ LinkedIn: [jimmyliao](https://linkedin.com/in/jimmyliao)\n",
        "- ğŸ“ Blog: [memo.jimmyliao.net](https://memo.jimmyliao.net)\n",
        "- ğŸ”— GitHub: [jimmyliao/trans-gemma](https://github.com/jimmyliao/trans-gemma)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpu-warning"
      },
      "source": [
        "---\n",
        "\n",
        "## âš ï¸ é‡è¦ï¼šå¿…é ˆä½¿ç”¨ GPU åŠ é€Ÿ\n",
        "\n",
        "**TranslateGemma éœ€è¦ GPU æ‰èƒ½æ­£å¸¸é‹ä½œ**ï¼Œå¦å‰‡ç¿»è­¯é€Ÿåº¦æœƒéå¸¸æ…¢ï¼š\n",
        "\n",
        "| ç¡¬é«” | æ¯é ç¿»è­¯æ™‚é–“ | 7 é ç¸½æ™‚é–“ |\n",
        "|------|-------------|----------|\n",
        "| âœ… **T4 GPU** | ~25 ç§’ | ~3 åˆ†é˜ |\n",
        "| âŒ CPU | ~15-20 åˆ†é˜ | ~2-3 å°æ™‚ |\n",
        "\n",
        "### ğŸ“Œ å¦‚ä½•å•Ÿç”¨ GPUï¼Ÿ\n",
        "\n",
        "**æ­¤ Notebook å·²é è¨­ä½¿ç”¨ T4 GPU**ï¼Œä½†è«‹ç¢ºèªï¼š\n",
        "\n",
        "1. é»æ“Šå³ä¸Šè§’æŸ¥çœ‹ã€Œé€£ç·šè‡³ä»£ç®¡çš„åŸ·è¡Œéšæ®µã€\n",
        "2. ç¢ºèªé¡¯ç¤º **ã€ŒT4ã€** è€Œéã€ŒPython 3ã€\n",
        "3. å¦‚æœä¸æ˜¯ T4ï¼š\n",
        "   - é»æ“Šå³ä¸Šè§’ â–¼ â†’ ã€Œè®Šæ›´åŸ·è¡Œéšæ®µé¡å‹ã€\n",
        "   - ç¡¬é«”åŠ é€Ÿå™¨ï¼šé¸æ“‡ **ã€ŒT4 GPUã€**\n",
        "   - é»æ“Šã€Œå„²å­˜ã€\n",
        "\n",
        "### ğŸ’¡ ç¢ºèª GPU å·²å•Ÿç”¨\n",
        "\n",
        "åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ç¢ºèªï¼š\n",
        "\n",
        "```python\n",
        "!nvidia-smi  # æ‡‰è©²çœ‹åˆ° T4 GPU è³‡è¨Š\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpu-check-header"
      },
      "source": [
        "## ğŸ’¡ ç¢ºèª GPU å·²å•Ÿç”¨\n",
        "\n",
        "**åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ç¢ºèªï¼š**\n",
        "\n",
        "- âœ… æ‡‰è©²çœ‹åˆ° `Tesla T4` GPU è³‡è¨Š\n",
        "- âŒ å¦‚æœçœ‹åˆ°éŒ¯èª¤è¨Šæ¯ï¼Œè«‹åˆ‡æ›åˆ° T4 GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpu-check-code"
      },
      "source": [
        "# ============================================\n",
        "# GPU Availability Check\n",
        "# ============================================\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    # åŸ·è¡Œ nvidia-smi ç¢ºèª GPU\n",
        "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, timeout=5)\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        # GPU å¯ç”¨\n",
        "        output = result.stdout\n",
        "        \n",
        "        # æª¢æŸ¥æ˜¯å¦æ˜¯ T4 GPU\n",
        "        if 'Tesla T4' in output or 'T4' in output:\n",
        "            print(\"âœ… GPU å·²å•Ÿç”¨ï¼šTesla T4\")\n",
        "            print(\"\\nğŸ“Š GPU è³‡è¨Šï¼š\")\n",
        "            # åªé¡¯ç¤ºé—œéµè¡Œ\n",
        "            for line in output.split('\\n'):\n",
        "                if 'Tesla T4' in line or 'GPU Name' in line or '|' in line[:5]:\n",
        "                    print(line)\n",
        "            print(\"\\nğŸš€ å¯ä»¥é–‹å§‹ç¿»è­¯äº†ï¼\")\n",
        "        else:\n",
        "            print(\"âš ï¸  åµæ¸¬åˆ° GPUï¼Œä½†ä¸æ˜¯ T4\")\n",
        "            print(\"\\nğŸ“Š ç•¶å‰ GPUï¼š\")\n",
        "            for line in output.split('\\n')[:15]:  # é¡¯ç¤ºå‰ 15 è¡Œ\n",
        "                print(line)\n",
        "            print(\"\\nğŸ’¡ æç¤ºï¼šå…¶ä»– GPU ä¹Ÿå¯ä»¥ä½¿ç”¨ï¼Œä½† T4 æ˜¯å…è²»ç‰ˆæœ€ä½³é¸æ“‡\")\n",
        "    else:\n",
        "        # nvidia-smi åŸ·è¡Œå¤±æ•—\n",
        "        raise RuntimeError(\"nvidia-smi command failed\")\n",
        "        \n",
        "except (subprocess.TimeoutExpired, FileNotFoundError, RuntimeError) as e:\n",
        "    # GPU ä¸å¯ç”¨\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"âŒ éŒ¯èª¤ï¼šæœªåµæ¸¬åˆ° GPUï¼\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nâš ï¸  ä½¿ç”¨ CPU ç¿»è­¯æœƒéå¸¸æ…¢ï¼š\")\n",
        "    print(\"   â€¢ CPU é€Ÿåº¦ï¼š15-20 åˆ†é˜/é \")\n",
        "    print(\"   â€¢ T4 GPU é€Ÿåº¦ï¼š25 ç§’/é \")\n",
        "    print(\"   â€¢ å·®è·ï¼š~40 å€ï¼\")\n",
        "    print(\"\\nğŸ”§ å¦‚ä½•å•Ÿç”¨ GPUï¼š\")\n",
        "    print(\"   1. é»æ“Šå³ä¸Šè§’ â–¼ â†’ è®Šæ›´åŸ·è¡Œéšæ®µé¡å‹\")\n",
        "    print(\"   2. ç¡¬é«”åŠ é€Ÿå™¨ï¼šé¸æ“‡ã€T4 GPUã€\")\n",
        "    print(\"   3. é»æ“Šã€å„²å­˜ã€\")\n",
        "    print(\"   4. Runtime æœƒé‡æ–°å•Ÿå‹•\")\n",
        "    print(\"   5. é‡æ–°åŸ·è¡Œæ­¤ Cell ç¢ºèª\")\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"â›” ç¨‹åºå·²åœæ­¢ï¼Œè«‹å•Ÿç”¨ GPU å¾Œé‡æ–°åŸ·è¡Œ\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "    \n",
        "    # æ‹‹å‡ºéŒ¯èª¤åœæ­¢åŸ·è¡Œ\n",
        "    raise RuntimeError(\n",
        "        \"âŒ GPU æœªå•Ÿç”¨ï¼è«‹åˆ‡æ›åˆ° T4 GPU å¾Œé‡æ–°åŸ·è¡Œã€‚\"\n",
        "        \"\\n\\næ­¥é©Ÿï¼šå³ä¸Šè§’ â–¼ â†’ è®Šæ›´åŸ·è¡Œéšæ®µé¡å‹ â†’ T4 GPU â†’ å„²å­˜\"\n",
        "    )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90ffe750-31f9-4d62-a2dc-f610d8794bda"
      },
      "source": [
        "## 1ï¸âƒ£ Setup: Clone Repository & Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone repository (single source of truth)\n",
        "!rm -rf trans-gemma\n",
        "!git clone https://github.com/jimmyliao/trans-gemma.git\n",
        "%cd trans-gemma\n",
        "\n",
        "# Install dependencies\n",
        "!pip install uv -q\n",
        "!uv pip install --system -e \".[examples]\""
      ],
      "metadata": {
        "id": "b9859387-a591-4fcd-8328-f87fd4dfd5d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58e6714a-856c-4996-bcf0-483db5247ebc"
      },
      "source": [
        "## 2ï¸âƒ£ HuggingFace Authentication\n",
        "\n",
        "**IMPORTANT:** TranslateGemma is a gated model. You need to:\n",
        "1. Get a HuggingFace token from [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)\n",
        "2. Accept model access at [https://huggingface.co/google/translategemma-4b-it](https://huggingface.co/google/translategemma-4b-it)\n",
        "\n",
        "### ğŸ” Configuration Methods (Choose ONE based on your environment)\n",
        "\n",
        "#### **Option A: Web Colab** (Using browser)\n",
        "1. Click the ğŸ”‘ icon on left sidebar\n",
        "2. Add secret: `HF_TOKEN` = your token\n",
        "3. Run the cell below â†’ Token loaded automatically from Colab Secrets\n",
        "\n",
        "#### **Option B: VS Code Colab Extension** (Using VS Code locally)\n",
        "\n",
        "**âš ï¸ Important:** Your local `.env` file is NOT automatically synced to remote Colab runtime!\n",
        "\n",
        "**Solution: Create .env in remote runtime**\n",
        "\n",
        "The cell below will:\n",
        "1. First check if `.env` exists in remote runtime\n",
        "2. If not found, prompt you to enter token\n",
        "3. Automatically create `.env` file in remote runtime\n",
        "4. Use this token for authentication\n",
        "\n",
        "This way, you only need to enter your token once per runtime session.\n",
        "\n",
        "#### **Option C: Manual Input Every Time** (Not recommended)\n",
        "Skip .env creation and enter token manually each time.\n",
        "\n",
        "---\n",
        "\n",
        "**What happens when you run the cell below?**\n",
        "1. Checks for `.env` in current directory (remote runtime)\n",
        "2. If not found, prompts for token and creates `.env`\n",
        "3. If found, reads token from `.env`\n",
        "4. Authenticates with HuggingFace\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8162de94-9717-43bf-a4a2-2cacabe04364"
      },
      "source": [
        "from huggingface_hub import login\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def get_hf_token():\n",
        "    \"\"\"Smart HF Token retrieval with .env creation for VS Code\"\"\"\n",
        "    \n",
        "    # Method 1: Try .env file in current directory\n",
        "    env_file = Path('.env')\n",
        "    \n",
        "    if env_file.exists():\n",
        "        try:\n",
        "            with open('.env', 'r') as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line.startswith('HF_TOKEN='):\n",
        "                        token = line.split('=', 1)[1].strip().strip('\"').strip(\"'\")\n",
        "                        if token:\n",
        "                            print(\"âœ… HF_TOKEN loaded from .env file\")\n",
        "                            return token\n",
        "            print(\"âš ï¸  .env file found but HF_TOKEN not set correctly\")\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸  Error reading .env: {e}\")\n",
        "    \n",
        "    # Method 2: Try environment variables\n",
        "    token = os.getenv('HF_TOKEN') or os.getenv('HUGGING_FACE_HUB_TOKEN')\n",
        "    if token:\n",
        "        print(\"âœ… HF_TOKEN loaded from environment variable\")\n",
        "        return token\n",
        "    \n",
        "    # Method 3: Try Colab Secrets (Web Colab only)\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        token = userdata.get('HF_TOKEN')\n",
        "        print(\"âœ… HF_TOKEN loaded from Colab Secrets (Web Colab)\")\n",
        "        return token\n",
        "    except Exception:\n",
        "        pass\n",
        "    \n",
        "    # Method 4: Prompt for token and create .env (VS Code friendly)\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"âš ï¸  HF_TOKEN not found - Creating .env file\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\nğŸ“ Please enter your HuggingFace token:\")\n",
        "    print(\"   Get token: https://huggingface.co/settings/tokens\")\n",
        "    print(\"   Accept access: https://huggingface.co/google/translategemma-4b-it\")\n",
        "    print(\"\\nğŸ’¡ Your token will be saved to .env for this runtime session\")\n",
        "    print()\n",
        "    \n",
        "    token = input(\"HuggingFace Token: \").strip()\n",
        "    \n",
        "    if token:\n",
        "        # Save to .env for future use in this session\n",
        "        try:\n",
        "            with open('.env', 'w') as f:\n",
        "                f.write(f\"HF_TOKEN={token}\\n\")\n",
        "            print(\"\\nâœ… Token saved to .env file (runtime session)\")\n",
        "            print(\"   Next time you run this cell, it will load automatically\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâš ï¸  Could not save to .env: {e}\")\n",
        "            print(\"   Token will work this time but won't persist\")\n",
        "        \n",
        "        return token\n",
        "    else:\n",
        "        raise ValueError(\"âŒ HF_TOKEN is required to use TranslateGemma\")\n",
        "\n",
        "# Authenticate\n",
        "try:\n",
        "    HF_TOKEN = get_hf_token()\n",
        "    os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "    login(token=HF_TOKEN)\n",
        "    print(\"\\nâœ… Successfully authenticated with HuggingFace\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ Authentication failed: {e}\\n\")\n",
        "    raise"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ecdbcf0-9ad8-4074-8cc4-53a43ca20c89"
      },
      "source": [
        "## 3ï¸âƒ£ Configuration: Bilingual Reading Settings\n",
        "\n",
        "**é…ç½®ä½ çš„è«–æ–‡å’Œç¿»è­¯è¨­å®š**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2c3c730-6c57-48cf-bc0b-2c94922a2468"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# arXiv Paper Configuration\n",
        "# ============================================\n",
        "\n",
        "# arXiv Paper ID (from URL: https://arxiv.org/abs/XXXX.XXXXX)\n",
        "ARXIV_ID = \"2601.09012v2\"  # TranslateGemma Technical Report\n",
        "\n",
        "# ============================================\n",
        "# Bilingual Reading Settings\n",
        "# ============================================\n",
        "\n",
        "# Enable bilingual mode (always recommended for learning)\n",
        "BILINGUAL_MODE = True\n",
        "\n",
        "# Target language\n",
        "TARGET_LANG = \"zh-TW\"  # Traditional Chinese\n",
        "SOURCE_LANG = \"en\"     # English\n",
        "\n",
        "# ============================================\n",
        "# Translation Sections (Page Ranges)\n",
        "# ============================================\n",
        "\n",
        "# ğŸš€ FULL TRANSLATION MODE\n",
        "# Define which sections to translate\n",
        "# Format: \"section_name\": (start_page, end_page)\n",
        "SECTIONS = {\n",
        "    \"abstract\": (1, 1),      # Abstract (Page 1)\n",
        "    \"method\": (3, 5),        # Method section (Pages 3-5)\n",
        "    \"experiments\": (7, 9),   # Experiments (Pages 7-9)\n",
        "}\n",
        "\n",
        "# ============================================\n",
        "# Display Settings\n",
        "# ============================================\n",
        "\n",
        "# Extract technical terms for glossary\n",
        "EXTRACT_TERMS = True\n",
        "\n",
        "# Display options\n",
        "DISPLAY_MODE = \"rich\"  # Options: \"simple\", \"rich\", \"html\"\n",
        "# - simple: Plain text (fast)\n",
        "# - rich: Colored boxes with side-by-side layout (recommended)\n",
        "# - html: HTML table (best for saving/sharing)\n",
        "\n",
        "# Save output to file\n",
        "SAVE_TO_FILE = True  # Save translation to HTML file\n",
        "\n",
        "# Debug mode (set to True to see detailed progress)\n",
        "DEBUG_MODE = False  # Enable detailed debug output\n",
        "\n",
        "# ============================================\n",
        "# Execution Mode (é¸æ“‡åŸ·è¡Œæ¨¡å¼)\n",
        "# ============================================\n",
        "\n",
        "# é¸æ“‡åŸ·è¡Œæ¨¡å¼ï¼š\n",
        "# - \"arxiv\": ç¿»è­¯ arXiv è«–æ–‡ï¼ˆä½¿ç”¨ä¸Šæ–¹çš„ ARXIV_IDï¼‰\n",
        "# - \"upload\": ä¸Šå‚³æœ¬åœ° PDF æª”æ¡ˆç¿»è­¯\n",
        "# - \"batch\": æ‰¹æ¬¡ç¿»è­¯å¤šç¯‡è«–æ–‡\n",
        "# - \"skip\": è·³éç¿»è­¯ï¼ˆåªè¼‰å…¥æ¨¡å‹ï¼‰\n",
        "\n",
        "MODE = \"arxiv\"  # é è¨­ï¼šç¿»è­¯ arXiv è«–æ–‡\n",
        "\n",
        "# æ‰¹æ¬¡è™•ç†è¨­å®šï¼ˆåªåœ¨ MODE = \"batch\" æ™‚ä½¿ç”¨ï¼‰\n",
        "BATCH_PAPERS = [\n",
        "    # Format: (arxiv_id, sections_dict)\n",
        "    # Example:\n",
        "    # (\"2601.09012v2\", {\"abstract\": (1, 1)}),\n",
        "    # (\"2312.11805v1\", {\"abstract\": (1, 1)}),\n",
        "]\n",
        "\n",
        "# Upload PDF è¨­å®šï¼ˆåªåœ¨ MODE = \"upload\" æ™‚ä½¿ç”¨ï¼‰\n",
        "UPLOAD_SECTIONS = {\n",
        "    \"section1\": (1, 3),  # ä¿®æ”¹ç‚ºä½ è¦ç¿»è­¯çš„é ç¢¼ç¯„åœ\n",
        "}\n",
        "TRANSLATE_DEBUG = False  # Show full translation output (for diagnosing extraction issues)\n",
        "\n",
        "# ============================================\n",
        "# Performance Note\n",
        "# ============================================\n",
        "# Using text-only mode for better quality and speed\n",
        "# Text mode: ~20-25s/page\n",
        "# All pages will be processed as pure text\n",
        "\n",
        "# ============================================\n",
        "# Summary\n",
        "# ============================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ğŸ¯ arXiv Bilingual Reader - Configuration\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nğŸ“„ Paper: arXiv:{ARXIV_ID}\")\n",
        "print(f\"ğŸŒ Translation: {SOURCE_LANG} â†’ {TARGET_LANG}\")\n",
        "print(f\"ğŸ“– Bilingual Mode: {'âœ… Enabled' if BILINGUAL_MODE else 'âŒ Disabled'}\")\n",
        "print(f\"ğŸ“º Display Mode: {DISPLAY_MODE}\")\n",
        "print(f\"ğŸ’¾ Save to file: {'âœ… Yes' if SAVE_TO_FILE else 'âŒ No'}\")\n",
        "print(f\"\\nğŸ“š Sections to translate:\")\n",
        "total_pages = 0\n",
        "for section, (start, end) in SECTIONS.items():\n",
        "    page_count = end - start + 1\n",
        "    total_pages += page_count\n",
        "    pages = f\"Page {start}\" if start == end else f\"Pages {start}-{end}\"\n",
        "    print(f\"   â€¢ {section.capitalize()}: {pages} ({page_count} pages)\")\n",
        "print(f\"\\nğŸš€ FULL MODE: Translating {total_pages} pages\")\n",
        "print(f\"âš¡ Mode: Text-only (fast and accurate)\")\n",
        "print(f\"   Estimated time: ~{int(total_pages * 23 / 60)} minutes {(total_pages * 23) % 60} seconds\")\n",
        "print(f\"\\nğŸ’¡ Ready to translate! Execute Cell 4 to start.\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "functions-header"
      },
      "source": [
        "## 4ï¸âƒ£-1 Helper Functions\n\n**å®šç¾©è¼”åŠ©å‡½æ•¸ï¼ˆå…§éƒ¨ä½¿ç”¨ï¼Œç„¡éœ€ä¿®æ”¹ï¼‰**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d02b1b5-c8fd-4382-90d3-86e85f13abed"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "import gc\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Add examples to path\n",
        "sys.path.insert(0, 'examples')\n",
        "sys.path.insert(0, 'examples/backends')\n",
        "\n",
        "# Import backends\n",
        "from transformers_backend import TransformersBackend\n",
        "\n",
        "# Import utilities\n",
        "import urllib.request\n",
        "import fitz  # PyMuPDF\n",
        "import re\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# ============================================\n",
        "# Install and import tqdm for progress bar\n",
        "# ============================================\n",
        "try:\n",
        "    from tqdm.auto import tqdm\n",
        "except ImportError:\n",
        "    !pip install tqdm -q\n",
        "    from tqdm.auto import tqdm\n",
        "\n",
        "# ============================================\n",
        "# Helper Functions\n",
        "# ============================================\n",
        "def download_arxiv(arxiv_id):\n",
        "    \"\"\"Download arXiv PDF\"\"\"\n",
        "    clean_id = arxiv_id.split('v')[0] if 'v' in arxiv_id else arxiv_id\n",
        "    url = f\"https://arxiv.org/pdf/{clean_id}.pdf\"\n",
        "    filename = f\"{arxiv_id}.pdf\"\n",
        "    \n",
        "    print(f\"ğŸ“¥ Downloading from arXiv: {arxiv_id}\")\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "    \n",
        "    doc = fitz.open(filename)\n",
        "    total_pages = len(doc)\n",
        "    doc.close()\n",
        "    \n",
        "    print(f\"âœ… Downloaded: {filename} ({total_pages} pages)\\n\")\n",
        "    return filename, total_pages\n",
        "\n",
        "def upload_pdf():\n",
        "    \"\"\"Upload PDF file from local machine\"\"\"\n",
        "    from google.colab import files\n",
        "    import os\n",
        "    \n",
        "    print(\"ğŸ“¤ è«‹ä¸Šå‚³ PDF æª”æ¡ˆ...\")\n",
        "    uploaded = files.upload()\n",
        "    \n",
        "    if not uploaded:\n",
        "        raise ValueError(\"âŒ æœªé¸æ“‡æª”æ¡ˆ\")\n",
        "    \n",
        "    # å–å¾—ç¬¬ä¸€å€‹ä¸Šå‚³çš„æª”æ¡ˆ\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    \n",
        "    if not filename.endswith(\".pdf\"):\n",
        "        raise ValueError(\"âŒ è«‹ä¸Šå‚³ PDF æª”æ¡ˆ\")\n",
        "    \n",
        "    doc = fitz.open(filename)\n",
        "    total_pages = len(doc)\n",
        "    doc.close()\n",
        "    \n",
        "    print(f\"âœ… å·²ä¸Šå‚³: {filename} ({total_pages} pages)\\n\")\n",
        "    return filename, total_pages\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model-loading-header"
      },
      "source": [
        "## 4ï¸âƒ£ Load Translation Model\n",
        "\n",
        "**âš ï¸ åªéœ€åŸ·è¡Œä¸€æ¬¡ï¼**\n",
        "\n",
        "- æ¨¡å‹è¼‰å…¥å¾Œæœƒä¿ç•™åœ¨è¨˜æ†¶é«”ä¸­\n",
        "- ç¿»è­¯ä¸åŒè«–æ–‡æ™‚**ä¸éœ€è¦é‡æ–°åŸ·è¡Œæ­¤ Cell**\n",
        "- åªæœ‰åœ¨ Runtime é‡å•Ÿå¾Œæ‰éœ€è¦é‡æ–°è¼‰å…¥\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "load-model"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Set debug environment variable\n",
        "if TRANSLATE_DEBUG:\n",
        "    os.environ['TRANSLATE_DEBUG'] = '1'\n",
        "\n",
        "# Add examples to path\n",
        "sys.path.insert(0, 'examples')\n",
        "sys.path.insert(0, 'examples/backends')\n",
        "\n",
        "# Import backends\n",
        "from transformers_backend import TransformersBackend\n",
        "\n",
        "# Load text backend\n",
        "print('ğŸ”„ Loading TranslateGemma model...\\n')\n",
        "text_backend = TransformersBackend()\n",
        "text_backend.load_model()\n",
        "print('âœ… TranslateGemma model ready!\\n')\n",
        "print('ğŸ’¡ æ¨¡å‹å·²è¼‰å…¥ï¼Œå¯ä»¥é–‹å§‹ç¿»è­¯è«–æ–‡äº†ï¼')\n",
        "print('   ä¸‹ä¸€æ­¥ï¼šåŸ·è¡Œ Cell 5 (Translate arXiv Paper)\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "translate-exec-header"
      },
      "source": [
        "## 5ï¸âƒ£ Translate arXiv Paper\n",
        "\n",
        "**ğŸ“ æ›´æ›è«–æ–‡ï¼Ÿåªéœ€ä¿®æ”¹ ARXIV_ID ä¸¦é‡æ–°åŸ·è¡Œæ­¤ Cellï¼**\n",
        "\n",
        "ä¸éœ€è¦é‡æ–°è¼‰å…¥æ¨¡å‹ï¼Œç›´æ¥ä¿®æ”¹ä¸‹æ–¹çš„åƒæ•¸å³å¯ï¼š\n",
        "\n",
        "```python\n",
        "# ç¯„ä¾‹ï¼šæ›æˆå…¶ä»–è«–æ–‡\n",
        "translate_arxiv_paper(\n",
        "    arxiv_id=\"2312.11805v1\",  # æ”¹é€™è£¡ï¼\n",
        "    sections={\"abstract\": (1, 1)},\n",
        "    target_lang=\"zh-TW\"\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "translate-exec"
      },
      "source": [
        "def translate_arxiv_paper(\n",
        "    arxiv_id,\n",
        "    sections,\n",
        "    source_lang=\"en\",\n",
        "    target_lang=\"zh-TW\",\n",
        "    bilingual_mode=True,\n",
        "    extract_terms=True,\n",
        "    save_to_file=True,\n",
        "    display_mode=\"rich\"\n",
        "):\n",
        "    \"\"\"Translate an arXiv paper\n",
        "    \n",
        "    Args:\n",
        "        arxiv_id: arXiv paper ID (e.g., '2601.09012v2')\n",
        "        sections: Dict of section_name: (start_page, end_page)\n",
        "        source_lang: Source language code (default: 'en')\n",
        "        target_lang: Target language code (default: 'zh-TW')\n",
        "        bilingual_mode: Show original and translation side-by-side\n",
        "        extract_terms: Extract technical terms for glossary\n",
        "        save_to_file: Save translation to HTML file\n",
        "        display_mode: 'simple', 'rich', or 'html'\n",
        "    \n",
        "    Returns:\n",
        "        results: List of translation results\n",
        "    \"\"\"\n",
        "    import time\n",
        "    import gc\n",
        "    import torch\n",
        "    \n",
        "    print(\"\\n\" + \"#\"*80)\n",
        "    print(\"# arXiv Bilingual Reader - Translation Started\")\n",
        "    print(\"#\"*80 + \"\\n\")\n",
        "    \n",
        "    # Download arXiv paper\n",
        "    pdf_path, total_pages = download_arxiv(arxiv_id)\n",
        "    \n",
        "    # Calculate pages to translate\n",
        "    total_pages_to_translate = sum(end - start + 1 for start, end in sections.values())\n",
        "    \n",
        "    print(f\"ğŸ“Š Translation plan:\")\n",
        "    print(f\"   â€¢ Mode: Text-only (fast and accurate)\")\n",
        "    print(f\"   â€¢ Total pages: {total_pages_to_translate}\")\n",
        "    print(f\"   â€¢ Display: {display_mode}\")\n",
        "    print(f\"   â€¢ Estimated time: ~{total_pages_to_translate * 23} seconds\\n\")\n",
        "    \n",
        "    all_terms = {}\n",
        "    results = []\n",
        "    \n",
        "    # Translate all pages\n",
        "    print(\"\\n\" + \"#\"*80)\n",
        "    print(\"# Translation in Progress\")\n",
        "    print(\"#\"*80 + \"\\n\")\n",
        "    \n",
        "    with tqdm(total=total_pages_to_translate, desc=\"ğŸ“– Translating\", unit=\"page\") as pbar:\n",
        "        for section_name, (start_page, end_page) in sections.items():\n",
        "            for page_num in range(start_page, end_page + 1):\n",
        "                pbar.set_description(f\"ğŸ“– {section_name.capitalize()} - Page {page_num}/{total_pages}\")\n",
        "                debug_print(f\"Starting page {page_num} in section {section_name}\")\n",
        "                \n",
        "                original_text = extract_text_from_page(pdf_path, page_num)\n",
        "                debug_print(f\"Extracted {len(original_text)} chars from page {page_num}\")\n",
        "                debug_print(f\"Text preview: {original_text[:150]}...\")\n",
        "                \n",
        "                if not original_text:\n",
        "                    debug_print(f\"Page {page_num} has no text, skipping\")\n",
        "                    print(f\"âš ï¸  Page {page_num}: No text found, skipping...\\n\")\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "                \n",
        "                start_time = time.time()\n",
        "                debug_print(f\"Calling translation API for page {page_num}...\")\n",
        "                result = text_backend.translate(\n",
        "                    original_text,\n",
        "                    source_lang=source_lang,\n",
        "                    target_lang=target_lang\n",
        "                )\n",
        "                time_taken = time.time() - start_time\n",
        "                translation = result['translation']\n",
        "                debug_print(f\"Translation received: {len(translation)} chars\")\n",
        "                debug_print(f\"Translation preview: {translation[:150]}...\")\n",
        "                \n",
        "                # Store result\n",
        "                results.append({\n",
        "                    'page_num': page_num,\n",
        "                    'section': section_name,\n",
        "                    'original': original_text,\n",
        "                    'translation': translation,\n",
        "                    'time': time_taken\n",
        "                })\n",
        "                debug_print(f\"Stored result for page {page_num}\")\n",
        "                \n",
        "                # Extract terms\n",
        "                if extract_terms:\n",
        "                    terms = extract_technical_terms(original_text, translation)\n",
        "                    all_terms.update(terms)\n",
        "                \n",
        "                pbar.update(1)\n",
        "    \n",
        "    # Display Results\n",
        "    print(\"\\n\" + \"#\"*80)\n",
        "    print(\"# Translation Results - Interactive Preview\")\n",
        "    print(\"#\"*80 + \"\\n\")\n",
        "    \n",
        "    if len(results) > 1:\n",
        "        print(f\"ğŸ“„ å…± {len(results)} é ç¿»è­¯çµæœ\")\n",
        "        print(f\"ğŸ’¡ å‘ä¸‹æ»¾å‹•æŸ¥çœ‹æ‰€æœ‰é é¢\\n\")\n",
        "    \n",
        "    # Display each page\n",
        "    for idx, result in enumerate(results):\n",
        "        display_bilingual_rich([result], 0)\n",
        "    \n",
        "    # Display technical terms glossary\n",
        "    if extract_terms and all_terms:\n",
        "        print(\"\\n\" + \"#\"*80)\n",
        "        print(\"# ğŸ“š Technical Terms Glossary\")\n",
        "        print(\"#\"*80 + \"\\n\")\n",
        "        \n",
        "        print(\"=\"*80)\n",
        "        print(\"å°ˆæ¥­è¡“èªå°ç…§è¡¨\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        for en, zh in sorted(all_terms.items()):\n",
        "            print(f\"{en:40} â†’ {zh}\")\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(f\"Total terms extracted: {len(all_terms)}\")\n",
        "        print(\"=\"*80)\n",
        "    \n",
        "    # Save Interactive HTML\n",
        "    if save_to_file:\n",
        "        html_output = generate_interactive_html(results, arxiv_id, source_lang, target_lang, all_terms)\n",
        "        output_filename = f\"translation_{arxiv_id}_{source_lang}-{target_lang}.html\"\n",
        "        \n",
        "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(html_output)\n",
        "        \n",
        "        print(f\"\\nğŸ’¾ Interactive HTML saved to: {output_filename}\")\n",
        "        print(f\"\\nâœ¨ Features:\")\n",
        "        print(f\"   â€¢ å·¦å³ç®­é ­æŒ‰éˆ•åˆ‡æ›é é¢\")\n",
        "        print(f\"   â€¢ éµç›¤ â† â†’ æ–¹å‘éµå¿«é€Ÿå°èˆª\")\n",
        "        print(f\"   â€¢ å›ºå®šå°èˆªæ¬„é¡¯ç¤ºç•¶å‰é é¢\")\n",
        "        print(f\"\\nğŸ“¥ ä½¿ç”¨ä¸‹æ–¹çš„ä¸‹è¼‰ cell ä¸‹è¼‰æª”æ¡ˆ\\n\")\n",
        "    \n",
        "    print(\"\\n\" + \"#\"*80)\n",
        "    print(\"# âœ… Translation Complete!\")\n",
        "    print(\"#\"*80 + \"\\n\")\n",
        "    print(\"ğŸ’¡ Summary:\")\n",
        "    print(f\"   â€¢ Translated {total_pages_to_translate} pages\")\n",
        "    print(f\"   â€¢ Sections: {', '.join(sections.keys())}\")\n",
        "    print(f\"   â€¢ Technical terms found: {len(all_terms)}\")\n",
        "    print(f\"   â€¢ Display mode: {display_mode}\")\n",
        "    if save_to_file:\n",
        "        print(f\"   â€¢ Interactive HTML: {output_filename}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# ============================================\n",
        "\n",
        "\n",
        "def translate_uploaded_pdf(\n",
        "    sections,\n",
        "    source_lang=\"en\",\n",
        "    target_lang=\"zh-TW\",\n",
        "    bilingual_mode=True,\n",
        "    extract_terms=True,\n",
        "    save_to_file=True,\n",
        "    display_mode=\"rich\"\n",
        "):\n",
        "    \"\"\"Translate an uploaded PDF file\"\"\"\n",
        "    import time\n",
        "    \n",
        "    print(\"\\n\" + \"#\"*80)\n",
        "    print(\"# PDF Bilingual Translator - Upload Mode\")\n",
        "    print(\"#\"*80 + \"\\n\")\n",
        "    \n",
        "    # Upload PDF\n",
        "    pdf_path, total_pages = upload_pdf()\n",
        "    \n",
        "    # Use same translation logic as arxiv\n",
        "    # è¤‡ç”¨ translate_arxiv_paper çš„æ ¸å¿ƒé‚è¼¯\n",
        "    total_pages_to_translate = sum(end - start + 1 for start, end in sections.values())\n",
        "    \n",
        "    print(f\"ğŸ“Š Translation plan:\")\n",
        "    print(f\"   â€¢ Mode: Text-only\")\n",
        "    print(f\"   â€¢ Total pages: {total_pages_to_translate}\")\n",
        "    print(f\"   â€¢ Estimated time: ~{total_pages_to_translate * 23} seconds\\n\")\n",
        "    \n",
        "    all_terms = {}\n",
        "    results = []\n",
        "    \n",
        "    with tqdm(total=total_pages_to_translate, desc=\"ğŸ“– Translating\", unit=\"page\") as pbar:\n",
        "        for section_name, (start_page, end_page) in sections.items():\n",
        "            for page_num in range(start_page, end_page + 1):\n",
        "                pbar.set_description(f\"ğŸ“– {section_name} - Page {page_num}/{total_pages}\")\n",
        "                \n",
        "                original_text = extract_text_from_page(pdf_path, page_num)\n",
        "                if not original_text:\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "                \n",
        "                start_time = time.time()\n",
        "                result = text_backend.translate(original_text, source_lang=source_lang, target_lang=target_lang)\n",
        "                time_taken = time.time() - start_time\n",
        "                \n",
        "                results.append({\n",
        "                    \"page_num\": page_num,\n",
        "                    \"section\": section_name,\n",
        "                    \"original\": original_text,\n",
        "                    \"translation\": result[\"translation\"],\n",
        "                    \"time\": time_taken\n",
        "                })\n",
        "                \n",
        "                if extract_terms:\n",
        "                    all_terms.update(extract_technical_terms(original_text, result[\"translation\"]))\n",
        "                \n",
        "                pbar.update(1)\n",
        "    \n",
        "    # Display and save (same as arxiv version)\n",
        "    for idx, result in enumerate(results):\n",
        "        display_bilingual_rich([result], 0)\n",
        "    \n",
        "    if save_to_file:\n",
        "        import os\n",
        "        pdf_basename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
        "        html_output = generate_interactive_html(results, pdf_basename, source_lang, target_lang, all_terms)\n",
        "        output_filename = f\"translation_{pdf_basename}_{source_lang}-{target_lang}.html\"\n",
        "        with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(html_output)\n",
        "        print(f\"\\nğŸ’¾ Saved: {output_filename}\")\n",
        "    \n",
        "    print(\"\\nâœ… Translation complete!\")\n",
        "    return results\n",
        "\n",
        "def batch_translate_papers(papers_list, source_lang=\"en\", target_lang=\"zh-TW\"):\n",
        "    \"\"\"Batch translate multiple arXiv papers\"\"\"\n",
        "    print(f\"\\nğŸš€ æ‰¹æ¬¡è™•ç† {len(papers_list)} ç¯‡è«–æ–‡...\\n\")\n",
        "    \n",
        "    all_results = []\n",
        "    \n",
        "    for idx, (arxiv_id, sections) in enumerate(papers_list, 1):\n",
        "        print(f\"\\n\" + \"=\"*80)\n",
        "        print(f\"ğŸ“„ Paper {idx}/{len(papers_list)}: {arxiv_id}\")\n",
        "        print(\"=\"*80 + \"\\n\")\n",
        "        \n",
        "        try:\n",
        "            results = translate_arxiv_paper(\n",
        "                arxiv_id=arxiv_id,\n",
        "                sections=sections,\n",
        "                source_lang=source_lang,\n",
        "                target_lang=target_lang,\n",
        "                bilingual_mode=BILINGUAL_MODE,\n",
        "                extract_terms=EXTRACT_TERMS,\n",
        "                save_to_file=SAVE_TO_FILE,\n",
        "                display_mode=\"simple\"\n",
        "            )\n",
        "            all_results.append((arxiv_id, results))\n",
        "            print(f\"\\nâœ… Completed: {arxiv_id}\\n\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ Error: {e}\\n\")\n",
        "    \n",
        "    print(f\"\\nğŸ‰ æ‰¹æ¬¡è™•ç†å®Œæˆï¼{len(all_results)}/{len(papers_list)} ç¯‡æˆåŠŸ\")\n",
        "    return all_results\n",
        "\n",
        "print(\"âœ… All translation functions loaded:\")\n",
        "print(\"   â€¢ translate_arxiv_paper()\")\n",
        "print(\"   â€¢ translate_uploaded_pdf()\")\n",
        "print(\"   â€¢ batch_translate_papers()\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batch-processing-header"
      },
      "source": [
        "## 6ï¸âƒ£ Batch Processing (Optional)\n",
        "\n",
        "**ä¸€æ¬¡ç¿»è­¯å¤šç¯‡è«–æ–‡**\n",
        "\n",
        "å¦‚æœä½ éœ€è¦ç¿»è­¯å¤šç¯‡è«–æ–‡ï¼Œå¯ä»¥ä½¿ç”¨æ‰¹æ¬¡è™•ç†åŠŸèƒ½ï¼š\n",
        "\n",
        "```python\n",
        "papers = [\n",
        "    (\"2601.09012v2\", {\"abstract\": (1, 1)}),  # TranslateGemma\n",
        "    (\"2312.11805v1\", {\"abstract\": (1, 1)}),  # Gemini\n",
        "    (\"2204.02311v1\", {\"abstract\": (1, 1)}),  # PaLM\n",
        "]\n",
        "\n",
        "for arxiv_id, sections in papers:\n",
        "    translate_arxiv_paper(arxiv_id, sections)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unified-execution"
      },
      "source": [
        "## 5ï¸âƒ£ Execute Translation\n",
        "\n",
        "**æ ¹æ“š Cell 3 çš„ MODE è¨­å®šè‡ªå‹•åŸ·è¡Œå°æ‡‰çš„ç¿»è­¯æ¨¡å¼**\n",
        "\n",
        "- ğŸ”µ `MODE = \"arxiv\"`: ç¿»è­¯å–®ç¯‡ arXiv è«–æ–‡\n",
        "- ğŸŸ¢ `MODE = \"upload\"`: ä¸Šå‚³æœ¬åœ° PDF æª”æ¡ˆç¿»è­¯\n",
        "- ğŸŸ¡ `MODE = \"batch\"`: æ‰¹æ¬¡ç¿»è­¯å¤šç¯‡è«–æ–‡\n",
        "- âšª `MODE = \"skip\"`: è·³éç¿»è­¯ï¼ˆåƒ…è¼‰å…¥æ¨¡å‹ï¼‰\n",
        "\n",
        "**åªéœ€åŸ·è¡Œæ­¤ Cellï¼Œæœƒè‡ªå‹•æ ¹æ“š MODE é¸æ“‡æ­£ç¢ºçš„ç¿»è­¯æ–¹å¼ï¼**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unified-execution-code"
      },
      "source": [
        "# ============================================\n",
        "# Unified Translation Execution\n",
        "# ============================================\n",
        "\n",
        "print(f\"\\nğŸ¯ åŸ·è¡Œæ¨¡å¼ï¼š{MODE}\\n\")\n",
        "\n",
        "if MODE == \"arxiv\":\n",
        "    # ========================================\n",
        "    # Mode 1: ç¿»è­¯ arXiv è«–æ–‡\n",
        "    # ========================================\n",
        "    print(\"ğŸ“„ æ¨¡å¼ï¼šç¿»è­¯ arXiv è«–æ–‡\")\n",
        "    print(f\"   è«–æ–‡ IDï¼š{ARXIV_ID}\")\n",
        "    print(f\"   ç« ç¯€ï¼š{list(SECTIONS.keys())}\\n\")\n",
        "    \n",
        "    results = translate_arxiv_paper(\n",
        "        arxiv_id=ARXIV_ID,\n",
        "        sections=SECTIONS,\n",
        "        source_lang=SOURCE_LANG,\n",
        "        target_lang=TARGET_LANG,\n",
        "        bilingual_mode=BILINGUAL_MODE,\n",
        "        extract_terms=EXTRACT_TERMS,\n",
        "        save_to_file=SAVE_TO_FILE,\n",
        "        display_mode=DISPLAY_MODE\n",
        "    )\n",
        "\n",
        "elif MODE == \"upload\":\n",
        "    # ========================================\n",
        "    # Mode 2: ä¸Šå‚³æœ¬åœ° PDF\n",
        "    # ========================================\n",
        "    print(\"ğŸ“¤ æ¨¡å¼ï¼šä¸Šå‚³æœ¬åœ° PDF æª”æ¡ˆ\")\n",
        "    print(f\"   ç« ç¯€ï¼š{list(UPLOAD_SECTIONS.keys())}\\n\")\n",
        "    \n",
        "    results = translate_uploaded_pdf(\n",
        "        sections=UPLOAD_SECTIONS,\n",
        "        source_lang=SOURCE_LANG,\n",
        "        target_lang=TARGET_LANG,\n",
        "        bilingual_mode=BILINGUAL_MODE,\n",
        "        extract_terms=EXTRACT_TERMS,\n",
        "        save_to_file=SAVE_TO_FILE,\n",
        "        display_mode=DISPLAY_MODE\n",
        "    )\n",
        "\n",
        "elif MODE == \"batch\":\n",
        "    # ========================================\n",
        "    # Mode 3: æ‰¹æ¬¡ç¿»è­¯\n",
        "    # ========================================\n",
        "    if not BATCH_PAPERS:\n",
        "        print(\"âš ï¸  æ‰¹æ¬¡è™•ç†æ¨¡å¼ï¼šè«‹åœ¨ Cell 3 çš„ BATCH_PAPERS æ¸…å–®ä¸­åŠ å…¥è«–æ–‡\")\n",
        "        print(\"\\nç¯„ä¾‹ï¼š\")\n",
        "        print('BATCH_PAPERS = [')\n",
        "        print('    (\"2601.09012v2\", {\"abstract\": (1, 1)}),')\n",
        "        print('    (\"2312.11805v1\", {\"abstract\": (1, 1)}),')\n",
        "        print(']')\n",
        "    else:\n",
        "        print(\"ğŸ“š æ¨¡å¼ï¼šæ‰¹æ¬¡ç¿»è­¯å¤šç¯‡è«–æ–‡\")\n",
        "        print(f\"   è«–æ–‡æ•¸é‡ï¼š{len(BATCH_PAPERS)}\\n\")\n",
        "        \n",
        "        results = batch_translate_papers(\n",
        "            papers_list=BATCH_PAPERS,\n",
        "            source_lang=SOURCE_LANG,\n",
        "            target_lang=TARGET_LANG\n",
        "        )\n",
        "\n",
        "elif MODE == \"skip\":\n",
        "    # ========================================\n",
        "    # Mode 4: è·³éç¿»è­¯\n",
        "    # ========================================\n",
        "    print(\"â­ï¸  æ¨¡å¼ï¼šè·³éç¿»è­¯\")\n",
        "    print(\"   æ¨¡å‹å·²è¼‰å…¥ï¼ŒæœªåŸ·è¡Œç¿»è­¯\")\n",
        "    print(\"\\nğŸ’¡ æç¤ºï¼š\")\n",
        "    print(\"   - å¯ä»¥æ‰‹å‹•å‘¼å« translate_arxiv_paper()\")\n",
        "    print(\"   - å¯ä»¥æ‰‹å‹•å‘¼å« translate_uploaded_pdf()\")\n",
        "    print(\"   - å¯ä»¥æ‰‹å‹•å‘¼å« batch_translate_papers()\")\n",
        "    results = None\n",
        "\n",
        "else:\n",
        "    # ========================================\n",
        "    # Invalid mode\n",
        "    # ========================================\n",
        "    print(f\"âŒ éŒ¯èª¤ï¼šæœªçŸ¥çš„ MODE = '{MODE}'\")\n",
        "    print(\"\\næœ‰æ•ˆçš„é¸é …ï¼š\")\n",
        "    print('  - MODE = \"arxiv\"   # ç¿»è­¯ arXiv è«–æ–‡')\n",
        "    print('  - MODE = \"upload\"  # ä¸Šå‚³æœ¬åœ° PDF')\n",
        "    print('  - MODE = \"batch\"   # æ‰¹æ¬¡ç¿»è­¯')\n",
        "    print('  - MODE = \"skip\"    # è·³éç¿»è­¯')\n",
        "    results = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "batch-processing"
      },
      "source": [
        "# ============================================\n",
        "# Batch Processing Function\n",
        "# ============================================\n",
        "\n",
        "def batch_translate_papers(papers_list, source_lang=\"en\", target_lang=\"zh-TW\"):\n",
        "    \"\"\"æ‰¹æ¬¡ç¿»è­¯å¤šç¯‡è«–æ–‡\n",
        "    \n",
        "    Args:\n",
        "        papers_list: List of (arxiv_id, sections_dict) tuples\n",
        "        source_lang: Source language\n",
        "        target_lang: Target language\n",
        "    \n",
        "    Returns:\n",
        "        List of (arxiv_id, results) tuples\n",
        "    \"\"\"\n",
        "    print(f\"\\nğŸš€ é–‹å§‹æ‰¹æ¬¡è™•ç† {len(papers_list)} ç¯‡è«–æ–‡...\\n\")\n",
        "    \n",
        "    all_results = []\n",
        "    \n",
        "    for idx, (arxiv_id, sections) in enumerate(papers_list, 1):\n",
        "        print(f\"\\n\" + \"=\"*80)\n",
        "        print(f\"ğŸ“„ Paper {idx}/{len(papers_list)}: arXiv:{arxiv_id}\")\n",
        "        print(\"=\"*80 + \"\\n\")\n",
        "        \n",
        "        try:\n",
        "            results = translate_arxiv_paper(\n",
        "                arxiv_id=arxiv_id,\n",
        "                sections=sections,\n",
        "                source_lang=source_lang,\n",
        "                target_lang=target_lang,\n",
        "                bilingual_mode=BILINGUAL_MODE,\n",
        "                extract_terms=EXTRACT_TERMS,\n",
        "                save_to_file=SAVE_TO_FILE,\n",
        "                display_mode=\"simple\"  # æ‰¹æ¬¡è™•ç†ç”¨ç°¡å–®æ¨¡å¼\n",
        "            )\n",
        "            all_results.append((arxiv_id, results))\n",
        "            print(f\"\\nâœ… Paper {idx} complete: {arxiv_id}\\n\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\nâŒ Error processing {arxiv_id}: {e}\\n\")\n",
        "            continue\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"ğŸ‰ æ‰¹æ¬¡è™•ç†å®Œæˆï¼å…±è™•ç† {len(all_results)}/{len(papers_list)} ç¯‡è«–æ–‡\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # é¡¯ç¤ºæ‰€æœ‰ç”Ÿæˆçš„æª”æ¡ˆ\n",
        "    print(\"\\nğŸ“‚ Generated Files:\")\n",
        "    for arxiv_id, _ in all_results:\n",
        "        filename = f\"translation_{arxiv_id}_{source_lang}-{target_lang}.html\"\n",
        "        print(f\"   â€¢ {filename}\")\n",
        "    \n",
        "    return all_results\n",
        "\n",
        "# ============================================\n",
        "# Usage Example (å–æ¶ˆè¨»è§£ä¾†ä½¿ç”¨)\n",
        "# ============================================\n",
        "\n",
        "# papers = [\n",
        "#     (\"2601.09012v2\", {\"abstract\": (1, 1)}),  # TranslateGemma\n",
        "#     (\"2312.11805v1\", {\"abstract\": (1, 1)}),  # Gemini\n",
        "#     (\"2204.02311v1\", {\"abstract\": (1, 1)}),  # PaLM\n",
        "# ]\n",
        "# \n",
        "# results = batch_translate_papers(\n",
        "#     papers_list=papers,\n",
        "#     source_lang=\"en\",\n",
        "#     target_lang=\"zh-TW\"\n",
        "# )\n",
        "\n",
        "print(\"ğŸ’¡ æ‰¹æ¬¡è™•ç†å‡½æ•¸å·²è¼‰å…¥\")\n",
        "print(\"   ä½¿ç”¨æ–¹å¼ï¼šå–æ¶ˆä¸Šæ–¹è¨»è§£æˆ–å‘¼å« batch_translate_papers()\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“¥ Download Translation\n",
        "\n",
        "**ä¸‹è¼‰ç¿»è­¯çµæœåˆ°æœ¬åœ°**\n",
        "\n",
        "Execute the cell below to download the HTML file to your local machine."
      ],
      "metadata": {
        "id": "362466ab-357b-4e4d-ae5d-ac3a1432d5db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Find HTML translation files\n",
        "html_files = [f for f in os.listdir('.') if f.startswith('translation_') and f.endswith('.html')]\n",
        "\n",
        "if html_files:\n",
        "    print(f\"ğŸ“„ æ‰¾åˆ° {len(html_files)} å€‹ç¿»è­¯æª”æ¡ˆï¼š\\n\")\n",
        "    \n",
        "    for html_file in html_files:\n",
        "        file_size = os.path.getsize(html_file) / 1024  # KB\n",
        "        print(f\"   â€¢ {html_file} ({file_size:.1f} KB)\")\n",
        "    \n",
        "    # Download the most recent one\n",
        "    html_file = html_files[0]\n",
        "    print(f\"\\nğŸ“¥ ä¸‹è¼‰æª”æ¡ˆï¼š{html_file}\")\n",
        "    print(\"   æª”æ¡ˆæœƒå‡ºç¾åœ¨ä½ çš„ç€è¦½å™¨ä¸‹è¼‰è³‡æ–™å¤¾...\\n\")\n",
        "    \n",
        "    files.download(html_file)\n",
        "    \n",
        "    print(\"\\nâœ… ä¸‹è¼‰å®Œæˆï¼\")\n",
        "    print(\"\\nğŸ’¡ æ¥ä¸‹ä¾†ï¼š\")\n",
        "    print(\"   1. åˆ°ç€è¦½å™¨çš„ä¸‹è¼‰è³‡æ–™å¤¾æ‰¾åˆ°æª”æ¡ˆ\")\n",
        "    print(\"   2. é›™æ“Šæª”æ¡ˆç”¨ç€è¦½å™¨é–‹å•Ÿ\")\n",
        "    print(\"   3. äº«å—å®Œç¾æ’ç‰ˆçš„é›™èªç¿»è­¯ï¼\")\n",
        "else:\n",
        "    print(\"âŒ æ‰¾ä¸åˆ° HTML æª”æ¡ˆ\")\n",
        "    print(f\"\\nç•¶å‰ç›®éŒ„ï¼š{os.getcwd()}\")\n",
        "    print(f\"\\næ‰€æœ‰æª”æ¡ˆï¼š\")\n",
        "    for f in sorted(os.listdir('.')):\n",
        "        print(f\"   â€¢ {f}\")"
      ],
      "metadata": {
        "id": "0113cf5d-133c-4fd6-94c3-419e59e4b8c2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "name": "arxiv-reader-colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}