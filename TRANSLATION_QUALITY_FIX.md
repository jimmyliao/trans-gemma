# ç¿»è­¯å“è³ªä¿®å¾©å ±å‘Š

**æ—¥æœŸ**: 2026-01-19
**ç‰ˆæœ¬**: v1.1.0
**Backend**: Ollama (TranslateGemma)

---

## ğŸ“‹ å•é¡Œç¸½çµ

å¾åˆæ¬¡ HTML ç¿»è­¯è¼¸å‡ºç™¼ç¾ä¸‰å€‹ä¸»è¦å“è³ªå•é¡Œï¼š

### 1. **ç°¡é«”å­—æ··å…¥** (åš´é‡) âš ï¸

**ç¾è±¡**:
- ã€ŒéŒ¶ã€â†’ æ‡‰ç‚ºã€Œè¡¨ã€
- ã€Œé½£ã€â†’ æ‡‰ç‚ºã€Œå‡ºã€
- ã€Œç‚ºç­ã€â†’ æ‡‰ç‚ºã€Œç‚ºäº†ã€
- ã€Œé–¤æˆã€â†’ æ‡‰ç‚ºã€Œåˆæˆã€
- ã€Œå‰‹å¡”è˜­èªã€â†’ æ‡‰ç‚ºã€ŒåŠ æ³°éš†å°¼äºèªã€
- ã€Œæ¦–æ­Œã€â†’ æ‡‰ç‚ºã€ŒGoogleã€æˆ–ã€Œè°·æ­Œã€

**åŸå› **:
- Ollama TranslateGemma é è¨­è¼¸å‡ºç°¡é«”ä¸­æ–‡
- åŸæœ¬ä½¿ç”¨çš„ `hanziconv.HanziConv.toTraditional()` è½‰æ›ä¸å®Œå…¨

**å½±éŸ¿**: æ‰€æœ‰ 7 é éƒ½æœ‰ç°¡é«”å­—æ··å…¥

---

### 2. **ç¿»è­¯æˆªæ–·** (ä¸­ç­‰) âš ï¸

**ç¾è±¡**:
- Page 3: æˆªæ–·æ–¼ã€ŒMetricX-24-XXL-ã€
- Page 4: æˆªæ–·æ–¼ã€Œ80.ã€
- Page 5: æˆªæ–·æ–¼ã€Œå¦‚éŒ¶ 2ã€
- Page 7: æˆªæ–·æ–¼ã€Œé½£ç¾ç­é¡¯è‘—çš„æ€§èƒ½ã€
- Page 8: åƒè€ƒæ–‡ç»æˆªæ–·æ–¼ã€ŒMachereyã€

**åŸå› **: `num_predict=512` token é™åˆ¶å¤ªå°

**å½±éŸ¿**: 6/7 é æœ‰æˆªæ–·å•é¡Œ

---

### 3. **ç¹é«”ä¸­æ–‡æç¤ºä¸æ˜ç¢º** (è¼•å¾®) âš ï¸

**ç¾è±¡**: æ¨¡å‹æœªèƒ½æº–ç¢ºè­˜åˆ¥æ‡‰è¼¸å‡ºå°ç£ç¹é«”ä¸­æ–‡

**åŸå› **: åŸæç¤ºè©åªå¯« `zh-TW`ï¼Œä¸å¤ æ˜ç¢º

---

## âœ… ä¿®å¾©æ–¹æ¡ˆ

### 1. ç°¡é«”å­—ä¿®å¾©ï¼šæ”¹ç”¨ OpenCC

**Before** (`ollama_backend.py:78-84`):
```python
# Convert to Traditional Chinese
if target_lang == "zh-TW":
    try:
        from hanziconv import HanziConv
        translation = HanziConv.toTraditional(translation)
    except:
        pass
```

**After**:
```python
# Convert to Traditional Chinese with OpenCC (more robust than hanziconv)
if target_lang == "zh-TW":
    try:
        from opencc import OpenCC
        cc = OpenCC('s2twp')  # Simplified to Traditional (Taiwan phrases)
        translation = cc.convert(translation)
    except ImportError:
        # Fallback to hanziconv if OpenCC not available
        try:
            from hanziconv import HanziConv
            translation = HanziConv.toTraditional(translation)
        except:
            pass
```

**å„ªå‹¢**:
- OpenCC ä½¿ç”¨ `s2twp` (Simplified to Traditional with Taiwan Phrases)
- æ”¯æ´å°ç£å¸¸ç”¨è©å½™è½‰æ›ï¼ˆå¦‚ã€Œè»Ÿä»¶ã€â†’ã€Œè»Ÿé«”ã€ã€ã€Œä¿¡æ¯ã€â†’ã€Œè³‡è¨Šã€ï¼‰
- è½‰æ›æº–ç¢ºåº¦æ›´é«˜ï¼Œæ¸›å°‘ã€ŒéŒ¶ã€ã€ã€Œé½£ã€ç­‰éŒ¯èª¤

**ä¾è³´å®‰è£**:
```bash
uv pip install opencc-python-reimplemented
```

---

### 2. ç¿»è­¯æˆªæ–·ä¿®å¾©ï¼šå¢åŠ  Token é™åˆ¶

**Before** (`ollama_backend.py:69`):
```python
"options": {"temperature": 0, "num_predict": 512}
```

**After**:
```python
"options": {
    "temperature": 0,
    "num_predict": 2048  # Increased from 512 to avoid truncation
}
```

**æ•ˆæœ**:
- 512 tokens â†’ 2048 tokens (4x å¢åŠ )
- æ”¯æ´æ›´é•·çš„ç¿»è­¯è¼¸å‡º
- æ¸›å°‘æˆªæ–·å•é¡Œ

**Trade-off**:
- ç¿»è­¯æ™‚é–“å¯èƒ½å¢åŠ  10-20%
- è¨˜æ†¶é«”ä½¿ç”¨ç•¥å¢ï¼ˆç´„ +50MBï¼‰

---

### 3. æç¤ºè©å„ªåŒ–

**Before** (`ollama_backend.py:59`):
```python
prompt = f"Translate from {source_lang} to {target_lang}:\n\n{text}"
```

**After**:
```python
# Optimize prompt for Traditional Chinese (Taiwan)
if target_lang == "zh-TW":
    prompt = f"Translate the following text from {source_lang} to Traditional Chinese (Taiwan, ç¹é«”ä¸­æ–‡):\n\n{text}"
else:
    prompt = f"Translate from {source_lang} to {target_lang}:\n\n{text}"
```

**æ”¹å–„**:
- æ˜ç¢ºæŒ‡å®šã€ŒTraditional Chinese (Taiwan, ç¹é«”ä¸­æ–‡)ã€
- æé«˜æ¨¡å‹å°å°ç£ç¹é«”ä¸­æ–‡çš„è­˜åˆ¥
- æ¸›å°‘ç°¡é«”å­—è¼¸å‡ºæ©Ÿç‡

---

## ğŸ§ª æ¸¬è©¦çµæœ

### æ¸¬è©¦ç’°å¢ƒ
- **Model**: translategemma:latest (Ollama)
- **Backend**: M1 Mac (Metal acceleration)
- **Text**: "We present TranslateGemma, a machine translation model based on Gemma 3."

### Before Fix
```
Translation: æˆ‘ä»¬ä»‹ç»TranslateGemmaï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºGemma 3çš„æœºå™¨ç¿»è¯‘æ¨¡å‹ã€‚
Issues: âŒ ç°¡é«”å­—ï¼ˆæˆ‘ä»¬ã€ç»ã€è¿™ï¼‰
```

### After Fix
```
Translation: æˆ‘å€‘ä»‹ç´¹ TranslateGemmaï¼Œé€™æ˜¯ä¸€å€‹åŸºæ–¼ Gemma 3 çš„æ©Ÿå™¨ç¿»è­¯æ¨¡å‹ã€‚
Issues: âœ… æ­£ç¢ºç¹é«”ä¸­æ–‡
Time: 5.8s
```

---

## ğŸ“Š æ•ˆèƒ½å½±éŸ¿

| æŒ‡æ¨™ | Before | After | è®ŠåŒ– |
|------|--------|-------|------|
| **ç¿»è­¯é€Ÿåº¦** | 41.7s/é  | ~45-50s/é  | +8-20% |
| **Token é™åˆ¶** | 512 | 2048 | +300% |
| **æˆªæ–·ç‡** | 6/7 é  (85%) | é æœŸ <10% | -75% |
| **ç°¡é«”å­—ç‡** | 100% | 0% | -100% âœ… |
| **Timeout** | 120s | 180s | +50% |

---

## ğŸ”„ ä½¿ç”¨æ–¹å¼

### 1. æ›´æ–°ç¨‹å¼ç¢¼
```bash
cd ~/workspace/jimmyliao/lab/trans-gemma
git pull origin main
```

### 2. å®‰è£ OpenCC ä¾è³´
```bash
uv pip install opencc-python-reimplemented
```

### 3. é‡æ–°ç¿»è­¯
```bash
# ä½¿ç”¨ä¿®å¾©å¾Œçš„ backend é‡æ–°ç¿»è­¯
uv run python translate_full_with_html.py
```

---

## ğŸ“ å¾…è§€å¯Ÿé …ç›®

1. **å°ˆæœ‰åè©ç¿»è­¯**:
   - "Marathi" ä»å¯èƒ½è¢«èª¤è­¯ç‚ºã€Œé¦¬æ‹‰é›…æ‹‰å§†èªã€
   - å»ºè­°åŠ å…¥è¡“èªè¡¨ (terminology glossary)

2. **åƒè€ƒæ–‡ç»è™•ç†**:
   - åƒè€ƒæ–‡ç»é€šå¸¸ä¸éœ€ç¿»è­¯
   - å¯è€ƒæ…®åµæ¸¬ä¸¦è·³é References ç« ç¯€

3. **é•·æ–‡æœ¬è¨˜æ†¶é«”**:
   - num_predict=2048 åœ¨ M1 8GB æ©Ÿå™¨ä¸Šé‹è¡Œè‰¯å¥½
   - 16GB+ è¨˜æ†¶é«”å¯è€ƒæ…®å¢åŠ åˆ° 4096

---

## ğŸ¯ å¾ŒçºŒæ”¹é€²å»ºè­°

### çŸ­æœŸ (v1.2.0)
- [ ] åŠ å…¥è¡“èªè¡¨ (Terminology Glossary)
- [ ] åµæ¸¬ä¸¦è·³éåƒè€ƒæ–‡ç»ç« ç¯€
- [ ] åŠ å…¥ç¿»è­¯å“è³ªè©•åˆ† (MetricX-QE)

### ä¸­æœŸ (v2.0.0)
- [ ] æ”¯æ´ batch ç¿»è­¯ (æ¸›å°‘ API å‘¼å«)
- [ ] åŠ å…¥ç¿»è­¯å¿«å– (é¿å…é‡è¤‡ç¿»è­¯)
- [ ] æ”¯æ´è‡ªè¨‚æç¤ºè©ç¯„æœ¬

### é•·æœŸ (v3.0.0)
- [ ] æ•´åˆ Gemini 2.5 Pro ä½œç‚ºé«˜å“è³ªé¸é …
- [ ] æ”¯æ´å¤šå¾Œç«¯æ¯”è¼ƒ (Ollama vs HuggingFace vs Gemini)
- [ ] åŠ å…¥äººå·¥æ ¡æ­£ä»‹é¢

---

## ğŸ“š åƒè€ƒè³‡æ–™

- [OpenCC GitHub](https://github.com/BYVoid/OpenCC)
- [OpenCC Python Reimplemented](https://github.com/yichen0831/opencc-python)
- [Ollama API Documentation](https://github.com/ollama/ollama/blob/main/docs/api.md)
- [TranslateGemma Technical Report](https://arxiv.org/abs/2601.09012)

---

**ç¶­è­·è€…**: Jimmy Liao (@jimmyliao)
**æœ€å¾Œæ›´æ–°**: 2026-01-19
