# arXiv é›™èªé–±è®€å™¨ï¼šç”¨ TranslateGemma æ‰“é€ å­¸è¡“è«–æ–‡çš„æœ€ä½³é–±è®€é«”é©—

**å‰¯æ¨™**ï¼šå¾çœ‹ä¸æ‡‚åˆ°å­¸å¾—æœƒ â€” å¦‚ä½•ç”¨ AI ç¿»è­¯åŒæ™‚æå‡è‹±æ–‡å­¸è¡“å¯«ä½œèƒ½åŠ›

---

## ç—›é»ï¼šè®€è‹±æ–‡è«–æ–‡çš„ä¸‰å¤§å›°å¢ƒ

ä½œç‚ºç ”ç©¶è€…æˆ–å·¥ç¨‹å¸«ï¼Œæ‚¨ä¸€å®šé‡éé€™äº›æƒ…æ³ï¼š

### å›°å¢ƒ 1ï¼šå°ˆæ¥­è¡“èªçœ‹ä¸æ‡‚ï¼Œç¿»è­¯è»Ÿé«”ä¹Ÿå¹«ä¸ä¸Šå¿™

```
åŸæ–‡ï¼š"We employ a two-stage fine-tuning process with
       MetricX-QE and AutoMQM for reinforcement learning..."

Google ç¿»è­¯ï¼š"æˆ‘å€‘æ¡ç”¨å…©éšæ®µå¾®èª¿éç¨‹ï¼Œä¸¦ä½¿ç”¨ MetricX-QE
            å’Œ AutoMQM é€²è¡Œå¼·åŒ–å­¸ç¿’..."
```

**å•é¡Œ**ï¼šç¿»è­¯æ˜¯ç¿»è­¯äº†ï¼Œä½† MetricX-QEã€AutoMQM æ˜¯ä»€éº¼ï¼Ÿreinforcement learning åœ¨é€™è£¡çš„è„ˆçµ¡æ˜¯ä»€éº¼æ„æ€ï¼Ÿ

### å›°å¢ƒ 2ï¼šæƒ³å­¸è‹±æ–‡å­¸è¡“å¯«ä½œï¼Œä½†ç¼ºä¹å°ç…§ç¯„æœ¬

çœ‹å®Œä¸­æ–‡ç¿»è­¯ï¼Œç†è§£äº†å…§å®¹ã€‚ä½†ä¸‹æ¬¡è‡ªå·±å¯«è«–æ–‡æ™‚ï¼š
- âŒ "evaluation results" åˆ°åº•æ€éº¼ç”¨ï¼Ÿ
- âŒ "demonstrate the effectiveness" çš„å¥å‹è¨˜ä¸èµ·ä¾†
- âŒ å°ˆæ¥­è¡“èªçš„è‹±æ–‡è¡¨é”æ–¹å¼æƒ³ä¸å‡ºä¾†

### å›°å¢ƒ 3ï¼šPDF å·¥å…·ç¿»è­¯ç ´å£æ’ç‰ˆï¼Œåœ–è¡¨æ¶ˆå¤±

å¸‚é¢ä¸Šçš„ PDF ç¿»è­¯å·¥å…·ï¼š
- âŒ ç¿»è­¯å¾Œç‰ˆé¢è·‘æ‰
- âŒ åœ–è¡¨å’Œæ–‡å­—çš„é—œä¿‚æ–·è£‚
- âŒ æ•¸å­¸å…¬å¼è®Šäº‚ç¢¼

**æˆ‘éœ€è¦çš„æ˜¯**ï¼šèƒ½ä¿ç•™åŸæ–‡ã€å°ç…§å­¸ç¿’ã€åˆä¸ç ´å£é–±è®€é«”é©—çš„å·¥å…·ã€‚

---

## è§£æ±ºæ–¹æ¡ˆï¼šTranslateGemma + arXiv é›™èªé–±è®€å™¨

### ä»€éº¼æ˜¯ TranslateGemmaï¼Ÿ

Google åœ¨ 2026 å¹´ 1 æœˆç™¼å¸ƒçš„é–‹æ”¾å¼æ©Ÿå™¨ç¿»è­¯æ¨¡å‹å®¶æ—ï¼ŒåŸºæ–¼ Gemma 3 æ¶æ§‹ï¼š

- ğŸŒ **æ”¯æ´ 38 ç¨®èªè¨€**ï¼ˆåŒ…å«ç¹é«”ä¸­æ–‡ï¼‰
- ğŸ¯ **å°ˆé–€å„ªåŒ–ç¿»è­¯å“è³ª**ï¼šé€é MetricX-QE å’Œ AutoMQM å¼·åŒ–å­¸ç¿’
- ğŸ“– **é–‹æºå¯ç”¨**ï¼šå¯åœ¨ HuggingFace ä¸‹è¼‰ï¼ŒT4 GPU å³å¯é‹è¡Œ
- ğŸ† **SOTA ç´šè¡¨ç¾**ï¼šåœ¨ WMT25 æ¸¬è©¦é›†ä¸Šè¡¨ç¾å„ªç•°

**æŠ€è¡“å ±å‘Š**ï¼š[arXiv:2601.09012](https://arxiv.org/abs/2601.09012)

### ç‚ºä»€éº¼ä¸ç”¨ ChatGPT/Claude ç¿»è­¯å°±å¥½ï¼Ÿ

TranslateGemma çš„å„ªå‹¢ï¼š

| ç‰¹æ€§ | TranslateGemma | ChatGPT/Claude |
|------|----------------|----------------|
| **å°ˆæ¥­å„ªåŒ–** | âœ… å°ˆé–€ç‚ºç¿»è­¯è¨“ç·´ | âš ï¸ é€šç”¨æ¨¡å‹ |
| **è¡“èªä¸€è‡´æ€§** | âœ… ä¿æŒåŸæ–‡è¡“èª | âŒ å¯èƒ½éåº¦æ„è­¯ |
| **æˆæœ¬** | âœ… å…è²»ï¼ˆè‡ªå»ºï¼‰| ğŸ’° API ä»˜è²» |
| **æ‰¹æ¬¡è™•ç†** | âœ… Colab GPU å…è²» | ğŸ’° å¤§é‡ç¿»è­¯æˆæœ¬é«˜ |
| **é›¢ç·šä½¿ç”¨** | âœ… ä¸‹è¼‰æ¨¡å‹å³å¯ | âŒ éœ€ç¶²è·¯é€£ç·š |

---

## å¯¦éš›æˆæœï¼šçœ‹çœ‹ç¿»è­¯æ•ˆæœ

### ç¿»è­¯å“è³ªç¯„ä¾‹

**è«–æ–‡**ï¼šTranslateGemma Technical Report (arXiv:2601.09012v2)

**åŸæ–‡ (Abstract)**ï¼š
```
We present TranslateGemma, a suite of open machine translation
models based on the Gemma 3 foundation models. To enhance the
inherent multilingual capabilities of Gemma 3 for the translation
task, we employ a two-stage fine-tuning process...
```

**TranslateGemma ç¿»è­¯**ï¼š
```
æˆ‘å€‘ä»‹ç´¹ TranslateGemmaï¼Œé€™å¥—åŸºæ–¼ Gemma 3 åŸºç¤æ¨¡å‹çš„é–‹
æ”¾å¼æ©Ÿå™¨ç¿»è­¯æ¨¡å‹ã€‚ç‚ºç­å¢å¼· Gemma 3 åœ¨ç¿»è­¯ä»»å‹™ä¸­çš„å›ºæœ‰å¤š
èªè¨€èƒ½åŠ›ï¼Œæˆ‘å€‘æ¡ç”¨å…©éšæ®µçš„å¾®èª¿éç¨‹ã€‚é¦–å…ˆï¼Œä½¿ç”¨å¤§é‡é«˜è³ªé‡
çš„å¤§è¦æ¨¡åœ–é–±è³‡æ–™é€²è¡Œç›£ç£å¾®èª¿...
```

### é›™èªå°ç…§ä»‹é¢

**ç‰¹è‰²**ï¼š
- ğŸ“– **å·¦å³å°ç…§**ï¼šåŸæ–‡ã€ç¿»è­¯ä¸¦åˆ—ï¼Œæ–¹ä¾¿å°æ¯”
- ğŸ¯ **å°ˆæ¥­è¡“èªä¿ç•™**ï¼šMetricX-QEã€AutoMQM ç­‰ä¿æŒåŸæ–‡
- ğŸ” **è¡“èªå°ç…§è¡¨**ï¼šè‡ªå‹•æå–ä¸­è‹±å°ç…§
- âŒ¨ï¸ **éµç›¤å°èˆª**ï¼šâ† â†’ å¿«é€Ÿåˆ‡æ›é é¢

---

## é–‹ç™¼éç¨‹ï¼šå¾æƒ³æ³•åˆ°å¯¦ä½œçš„ 4 è¼ªè¿­ä»£

### ç¬¬ 1 è¼ªï¼šåŸºæœ¬ç¿»è­¯åŠŸèƒ½

**ç›®æ¨™**ï¼šè®“ TranslateGemma è·‘èµ·ä¾†

**é‡åˆ°çš„å•é¡Œ**ï¼š
```python
# å®˜æ–¹ç¯„ä¾‹
target_lang = "zh-TW"  # è¨­å®šç¹é«”ä¸­æ–‡

# çµæœï¼šè¼¸å‡ºç°¡é«”ä¸­æ–‡ ğŸ˜±
"æˆ‘ä»¬ä»‹ç» TranslateGemma..."  # ç®€ä½“ï¼
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼šç™¼ç¾ TranslateGemma çš„ `zh-TW` bug
```python
# åŠ å…¥å¾Œè™•ç†
from hanziconv import HanziConv
translation = HanziConv.toTraditional(translation)
```

âœ… **æˆæœ**ï¼šæˆåŠŸè¼¸å‡ºç¹é«”ä¸­æ–‡

---

### ç¬¬ 2 è¼ªï¼šè¨˜æ†¶é«”ç®¡ç†

**ç›®æ¨™**ï¼šåœ¨ Colab T4 GPU (15GB) ä¸Šç¿»è­¯å®Œæ•´è«–æ–‡

**é‡åˆ°çš„å•é¡Œ**ï¼š
```
OutOfMemoryError: CUDA out of memory.
Tried to allocate 2.34 GiB (GPU 0; 14.76 GiB total capacity)
```

**åŸå› åˆ†æ**ï¼š
- Text backendï¼š8 GB
- Multimodal backendï¼š7 GB
- **åŒæ™‚è¼‰å…¥ï¼š15 GB** âŒ è¶…éé™åˆ¶

**è§£æ±ºæ–¹æ¡ˆ**ï¼šSequential loading
```python
# Phase 1: Text pages
text_backend = TransformersBackend()
text_backend.load_model()
# ... translate text pages ...
del text_backend.model
gc.collect()
torch.cuda.empty_cache()

# Phase 2: Image pages (if needed)
image_backend = TransformersMultimodalBackend()
image_backend.load_model()
# ... translate image pages ...
```

âœ… **æˆæœ**ï¼šè¨˜æ†¶é«”ä½¿ç”¨å¾ 15GB â†’ 8GB

---

### ç¬¬ 3 è¼ªï¼šä½¿ç”¨è€…é«”é©—å„ªåŒ–

**å•é¡Œç™¼ç¾**ï¼šç¬¬ä¸€å€‹æ¸¬è©¦ç”¨æˆ¶ï¼ˆå°±æ˜¯æˆ‘ï¼‰ç”¨ CPU è·‘äº† 30 åˆ†é˜... ğŸ˜±

**æ•ˆèƒ½å°æ¯”**ï¼š

| ç¡¬é«” | æ¯é ç¿»è­¯æ™‚é–“ | 7 é ç¸½æ™‚é–“ | é«”é©— |
|------|-------------|-----------|------|
| CPU | 15-20 åˆ†é˜ | 2-3 å°æ™‚ | âŒâŒâŒ ä¸å¯æ¥å— |
| T4 GPU | 25 ç§’ | 3 åˆ†é˜ | âœ…âœ…âœ… æµæš¢ |

**æ”¹é€²æªæ–½**ï¼š

1. **è¨­å®šé è¨­ GPU Runtime**
```json
{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm"
    }
  }
}
```

2. **æ–°å¢é†’ç›®è­¦å‘Š**
```markdown
âš ï¸ é‡è¦ï¼šå¿…é ˆä½¿ç”¨ GPU åŠ é€Ÿ

TranslateGemma éœ€è¦ GPU æ‰èƒ½æ­£å¸¸é‹ä½œ

å¦‚ä½•ç¢ºèªï¼š
1. é»æ“Šå³ä¸Šè§’æŸ¥çœ‹ã€Œé€£ç·šè‡³ä»£ç®¡çš„åŸ·è¡Œéšæ®µã€
2. ç¢ºèªé¡¯ç¤ºã€ŒT4ã€è€Œéã€ŒPython 3ã€
```

âœ… **æˆæœ**ï¼šç”¨æˆ¶ä¸æœƒå†è¸© CPU çš„å‘

---

### ç¬¬ 4 è¼ªï¼šäº’å‹•é«”é©—

**ç›®æ¨™**ï¼šè®“ç¿»è­¯çµæœåƒé–±è®€å™¨ï¼Œä¸åªæ˜¯æ–‡å­—æª”

**å¯¦ä½œåŠŸèƒ½**ï¼š

1. **é€²åº¦æ¢é¡¯ç¤º**
```python
from tqdm.auto import tqdm

with tqdm(total=7, desc="ğŸ“– Translating", unit="page") as pbar:
    for page_num in pages:
        pbar.set_description(f"ğŸ“– Page {page_num}/{total_pages}")
        # ... translate ...
        pbar.update(1)
```

2. **Rich HTML è¼¸å‡º**
   - é›™æ¬„å°ç…§æ’ç‰ˆ
   - æ¼¸å±¤è‰²æ¨™é¡Œ
   - ç¿»è­¯æ™‚é–“é¡¯ç¤º

3. **äº’å‹•å¼å°èˆª**
```javascript
// éµç›¤å¿«æ·éµ
document.addEventListener('keydown', (e) => {
    if (e.key === 'ArrowLeft') prevPage();
    else if (e.key === 'ArrowRight') nextPage();
});
```

4. **ä¸€éµä¸‹è¼‰**
```python
from google.colab import files
files.download(html_file)
```

âœ… **æˆæœ**ï¼šå¾ã€Œç¿»è­¯å·¥å…·ã€è®Šæˆã€Œé–±è®€å™¨ã€

---

## ä½¿ç”¨æŒ‡å—ï¼š5 åˆ†é˜é–‹å§‹ä½¿ç”¨

### Step 1: é–‹å•Ÿ Colab Notebook

é»æ“Š Badge ç›´æ¥é–‹å•Ÿï¼š

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jimmyliao/trans-gemma/blob/main/arxiv-reader-colab.ipynb)

**é‡è¦**ï¼šç¢ºèªå³ä¸Šè§’é¡¯ç¤ºã€Œé€£ç·šè‡³ä»£ç®¡çš„åŸ·è¡Œéšæ®µ: T4ã€

### Step 2: è¨­å®š HuggingFace Token

TranslateGemma æ˜¯ gated modelï¼Œéœ€è¦ï¼š

1. åˆ° [HuggingFace Settings](https://huggingface.co/settings/tokens) å»ºç«‹ Token
2. åˆ° [TranslateGemma é é¢](https://huggingface.co/google/translategemma-4b-it) æ¥å—æˆæ¬Š

**Web Colab ç”¨æˆ¶**ï¼š
- é»æ“Šå·¦å´ ğŸ”‘ åœ–ç¤º
- æ–°å¢ Secretï¼š`HF_TOKEN` = ä½ çš„ token

**VS Code Colab Extension ç”¨æˆ¶**ï¼š
- åŸ·è¡Œ Cell 4 æ™‚æœƒæç¤ºè¼¸å…¥ token
- è‡ªå‹•å»ºç«‹ `.env` æª”æ¡ˆï¼ˆsession å…§æœ‰æ•ˆï¼‰

### Step 3: é…ç½®è«–æ–‡ ID å’Œç¿»è­¯ç¯„åœ

```python
# Cell 6: Configuration

# arXiv Paper ID
ARXIV_ID = "2601.09012v2"  # æ”¹æˆä½ æƒ³ç¿»è­¯çš„è«–æ–‡

# ç¿»è­¯ç« ç¯€ï¼ˆé ç¢¼ç¯„åœï¼‰
SECTIONS = {
    "abstract": (1, 1),      # æ‘˜è¦
    "method": (3, 5),        # æ–¹æ³•è«–
    "experiments": (7, 9),   # å¯¦é©—çµæœ
}

# ç›®æ¨™èªè¨€
TARGET_LANG = "zh-TW"  # ç¹é«”ä¸­æ–‡
```

### Step 4: åŸ·è¡Œç¿»è­¯

åŸ·è¡Œ Cell 8ï¼Œç­‰å¾…ç´„ 3 åˆ†é˜ï¼š

```
ğŸ“¥ Downloading from arXiv: 2601.09012v2
âœ… Downloaded: 2601.09012v2.pdf (12 pages)

ğŸ”„ Loading text backend...
âœ… Text backend ready

ğŸ“– Translating: 7 pages
  Abstract - Page 1/12: 25.9s
  Method - Page 3/12: 22.1s
  Method - Page 4/12: 23.4s
  ...

âœ… Translation Complete!
ğŸ’¾ Interactive HTML saved to: translation_2601.09012v2_en-zh-TW.html
```

### Step 5: ä¸‹è¼‰ HTML æª”æ¡ˆ

åŸ·è¡Œ Cell 11ï¼ˆDownload cellï¼‰ï¼š

```python
files.download('translation_2601.09012v2_en-zh-TW.html')
```

åœ¨ç€è¦½å™¨é–‹å•Ÿ HTMLï¼š
- ğŸ’¡ ä½¿ç”¨ â† â†’ æ–¹å‘éµåˆ‡æ›é é¢
- ğŸ“– å·¦å³å°ç…§åŸæ–‡å’Œç¿»è­¯
- ğŸ“š æ»¾å‹•åˆ°æœ€ä¸‹æ–¹æŸ¥çœ‹è¡“èªå°ç…§è¡¨

---

## æŠ€è¡“ç´°ç¯€ï¼šçµ¦é€²éšè®€è€…

### æ¶æ§‹è¨­è¨ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  arxiv-reader-colab.ipynb (ä½¿ç”¨è€…ä»‹é¢)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚ transformers â”‚  â”‚ transformers â”‚
â”‚   _backend   â”‚  â”‚  _multimodal â”‚
â”‚  (Text only) â”‚  â”‚   _backend   â”‚
â”‚   8GB RAM    â”‚  â”‚  (with vision)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ TranslateGemma   â”‚
        â”‚ 4B parameters    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Memory Management Strategy

**å•é¡Œ**ï¼šColab T4 GPU åªæœ‰ 15GB VRAM

**è§£æ±ºæ–¹æ¡ˆ**ï¼šSequential backend loading

```python
# æ™ºæ…§è¨˜æ†¶é«”ç®¡ç†
def translate_pages(sections):
    results = []

    # Phase 1: Text-only pages
    text_backend = TransformersBackend()
    text_backend.load_model()

    for page in text_pages:
        result = text_backend.translate(page)
        results.append(result)

    # é‡‹æ”¾è¨˜æ†¶é«”
    del text_backend.model
    gc.collect()
    torch.cuda.empty_cache()

    # Phase 2: Image pages (if needed)
    if has_image_pages:
        image_backend = TransformersMultimodalBackend()
        image_backend.load_model()
        # ...

    return results
```

**æ•ˆæœ**ï¼š
- ç†è«–è¨˜æ†¶é«”éœ€æ±‚ï¼š15 GB
- å¯¦éš›ä½¿ç”¨ï¼š8 GB
- ç¯€çœï¼š47%

### Authentication Flow

æ”¯æ´ 4 ç¨®èªè­‰æ–¹å¼ï¼ˆå„ªå…ˆé †åºï¼‰ï¼š

```python
def get_hf_token():
    # 1. .env æª”æ¡ˆï¼ˆVS Code Colabï¼‰
    if Path('.env').exists():
        return read_from_env()

    # 2. ç’°å¢ƒè®Šæ•¸
    if os.getenv('HF_TOKEN'):
        return os.getenv('HF_TOKEN')

    # 3. Colab Secretsï¼ˆWeb Colabï¼‰
    try:
        from google.colab import userdata
        return userdata.get('HF_TOKEN')
    except:
        pass

    # 4. æ‰‹å‹•è¼¸å…¥ + å»ºç«‹ .env
    token = input("HuggingFace Token: ")
    save_to_env(token)
    return token
```

**é‡è¦ç™¼ç¾**ï¼šVS Code Colab Extension ä¸æ”¯æ´ `userdata.get()`
- è§£æ±ºæ–¹æ¡ˆï¼šåœ¨ remote runtime å»ºç«‹ `.env`
- åƒè€ƒæ–‡æª”ï¼š[VSCODE-COLAB-ANALYSIS.md](https://github.com/jimmyliao/trans-gemma/blob/main/VSCODE-COLAB-ANALYSIS.md)

---

## å¯¦éš›æ‡‰ç”¨å ´æ™¯

### å ´æ™¯ 1ï¼šç ”ç©¶ç”Ÿè®€ Related Work

**éœ€æ±‚**ï¼šå¿«é€Ÿç€è¦½ 50 ç¯‡è«–æ–‡çš„æ‘˜è¦ï¼Œç¯©é¸ç›¸é—œæ–‡ç»

**ä½¿ç”¨æ–¹å¼**ï¼š
```python
SECTIONS = {
    "abstract": (1, 1),  # åªç¿»è­¯æ‘˜è¦
}
```

**æ•ˆæœ**ï¼š
- æ¯ç¯‡è«–æ–‡ ~25 ç§’
- 50 ç¯‡ ~20 åˆ†é˜
- æ¯”é€å­—è®€è‹±æ–‡å¿« 10 å€

### å ´æ™¯ 2ï¼šæ·±å…¥ç ”è®€é‡è¦è«–æ–‡

**éœ€æ±‚**ï¼šç†è§£æ ¸å¿ƒæ–¹æ³•è«–ï¼Œå­¸ç¿’è‹±æ–‡å¯«ä½œ

**ä½¿ç”¨æ–¹å¼**ï¼š
```python
SECTIONS = {
    "introduction": (1, 2),
    "method": (3, 7),
    "experiments": (8, 12),
    "conclusion": (13, 14),
}
```

**ä½¿ç”¨æŠ€å·§**ï¼š
1. å…ˆçœ‹ä¸­æ–‡ç†è§£å…§å®¹
2. å°ç…§è‹±æ–‡å­¸ç¿’è¡¨é”æ–¹å¼
3. è¨˜éŒ„å°ˆæ¥­è¡“èªå°ç…§è¡¨
4. ç·´ç¿’ç”¨è‹±æ–‡è¤‡è¿°é‡é»

### å ´æ™¯ 3ï¼šæº–å‚™è«–æ–‡å¯«ä½œ

**éœ€æ±‚**ï¼šå­¸ç¿’ç‰¹å®šé ˜åŸŸçš„å­¸è¡“è‹±æ–‡å¯«ä½œ

**ä½¿ç”¨æ–¹å¼**ï¼š
1. æ”¶é›†åŒé ˜åŸŸé ‚æœƒè«–æ–‡ 5-10 ç¯‡
2. ç¿»è­¯ Introduction å’Œ Method sections
3. æ•´ç†å¸¸ç”¨å¥å‹å’Œè¡“èª
4. å»ºç«‹å€‹äººå¯«ä½œåƒè€ƒåº«

---

## FAQï¼šå¸¸è¦‹å•é¡Œ

### Q1: ç‚ºä»€éº¼ä¸ç›´æ¥ç”¨ Google Translateï¼Ÿ

**ç­”**ï¼š
- Google Translateï¼šé€šç”¨ç¿»è­¯ï¼Œå¯èƒ½éåº¦æ„è­¯
- TranslateGemmaï¼šä¿ç•™å­¸è¡“è¡“èªï¼Œé©åˆå­¸ç¿’
- é›™èªå°ç…§ï¼šåŒæ™‚å¸æ”¶å…§å®¹å’Œèªè¨€

### Q2: å¯ä»¥ç¿»è­¯ä¸­æ–‡è«–æ–‡æˆè‹±æ–‡å—ï¼Ÿ

**ç­”**ï¼šå¯ä»¥ï¼åªéœ€èª¿æ•´åƒæ•¸ï¼š

```python
SOURCE_LANG = "zh-TW"  # æˆ– "zh-CN"
TARGET_LANG = "en"
```

### Q3: Colab å…è²»ç‰ˆå¤ ç”¨å—ï¼Ÿ

**ç­”**ï¼š
- âœ… **T4 GPU**ï¼šå…è²»ç‰ˆå¯ç”¨ï¼Œé€Ÿåº¦ ~25 ç§’/é 
- âš ï¸ **ä½¿ç”¨æ™‚æ•¸é™åˆ¶**ï¼šå…è²»ç‰ˆç´„ 12-15 å°æ™‚/é€±
- ğŸ’¡ **å–®ç¯‡è«–æ–‡ (10-20 é )**ï¼š5-10 åˆ†é˜ï¼Œå®Œå…¨å¤ ç”¨

---

## ç¸½çµï¼šå¾å·¥å…·åˆ°æ–¹æ³•è«–çš„è½‰è®Š

### ä¸åªæ˜¯ç¿»è­¯å·¥å…·

é€™å€‹å°ˆæ¡ˆçš„æ ¸å¿ƒåƒ¹å€¼ä¸åœ¨æ–¼ã€ŒæŠŠè‹±æ–‡è®Šä¸­æ–‡ã€ï¼Œè€Œåœ¨æ–¼ï¼š

1. **é›™èªå­¸ç¿’æ³•**ï¼šåŒæ™‚å¸æ”¶å…§å®¹å’Œèªè¨€
2. **è¡“èªç´¯ç©**ï¼šå»ºç«‹å€‹äººå­¸è¡“è©å½™åº«
3. **å¯«ä½œåƒè€ƒ**ï¼šå¾é–±è®€åˆ°å¯«ä½œçš„æ©‹æ¨‘

### é–‹æºèˆ‡ç¤¾ç¾¤

**GitHub Repository**: [jimmyliao/trans-gemma](https://github.com/jimmyliao/trans-gemma)

åŒ…å«ï¼š
- âœ… arXiv Bilingual Readerï¼ˆæœ¬æ–‡ä»‹ç´¹ï¼‰
- âœ… Document Translatorï¼ˆé€šç”¨æ–‡ä»¶ç¿»è­¯ï¼‰
- âœ… VS Code Colab Extension æ”¯æ´åˆ†æ
- âœ… å®Œæ•´æŠ€è¡“æ–‡æª”

---

## ç«‹å³é–‹å§‹ä½¿ç”¨

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jimmyliao/trans-gemma/blob/main/arxiv-reader-colab.ipynb)

**5 åˆ†é˜å…§**ï¼Œæ‚¨å°±èƒ½ï¼š
1. ç¿»è­¯ç¬¬ä¸€ç¯‡è«–æ–‡
2. ä¸‹è¼‰é›™èª HTML
3. é–‹å§‹å­¸ç¿’ä¹‹æ—…

**è¨˜å¾—**ï¼šé¸æ“‡ T4 GPUï¼Œå¦å‰‡æœƒç­‰å¾ˆä¹… ğŸ˜‰

---

## é—œæ–¼ä½œè€…

**Jimmy Liao** - AI Google Developer Expert (GDE), CTO/Co-Founder

- ğŸ¦ Twitter: [@jimmyliao](https://twitter.com/jimmyliao)
- ğŸ’¼ LinkedIn: [jimmyliao](https://linkedin.com/in/jimmyliao)
- ğŸ“ Blog: [memo.jimmyliao.net](https://memo.jimmyliao.net)
- ğŸ”— GitHub: [jimmyliao](https://github.com/jimmyliao)

**å¦‚æœè¦ºå¾—æœ‰å¹«åŠ©ï¼Œæ­¡è¿**ï¼š
- â­ åœ¨ GitHub çµ¦å€‹ Star
- ğŸ“¢ åˆ†äº«çµ¦éœ€è¦çš„æœ‹å‹
- ğŸ’¬ ç•™è¨€åˆ†äº«ä½ çš„ä½¿ç”¨å¿ƒå¾—

---

*æ–‡ç« ç™¼å¸ƒæ—¥æœŸï¼š2026-01-19*
*æœ€å¾Œæ›´æ–°ï¼š2026-01-19*
